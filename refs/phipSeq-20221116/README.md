
#	refs/refseq/phipSeq-20221116



```

NP_000468.1_albumin_preproprotein -> ../mRNA_Prot-20210528/NP_000468.1_albumin_preproprotein/
NP_040190.1_envelope_glycoprotein_E_Human_alphaherpesvirus_3 -> ../viral-20220923/NP_040190.1_envelope_glycoprotein_E_Human_alphaherpesvirus_3
NP_579894.2_Envelope_surface_glycoprotein_gp120_Human_immunodeficiency_virus_1 -> ../viral-20220923/NP_579894.2_Envelope_surface_glycoprotein_gp120_Human_immunodeficiency_virus_1/

ls -1 NP_*/*fa
NP_000468.1_albumin_preproprotein/NP_000468.1_albumin_preproprotein.fa
NP_040190.1_envelope_glycoprotein_E_Human_alphaherpesvirus_3/NP_040190.1_envelope_glycoprotein_E_Human_alphaherpesvirus_3.fa
NP_579894.2_Envelope_surface_glycoprotein_gp120_Human_immunodeficiency_virus_1/NP_579894.2_Envelope_surface_glycoprotein_gp120_Human_immunodeficiency_virus_1.fa

cat NP_*/*fa > select_sequences.faa


nohup ./phipseq.bash 56 28 select_sequences.faa > phipseq.56.28.out.txt 2>&1 &

```

##	20231213

```
module load bowtie
mkdir bowtie_index
bowtie-build -q oligos-ref-56-28.fasta bowtie_index/mylibrary
```






##	Eventually


From `Larman paper (protocol of PhIP_Seq)(2019).pdf`

Section `Processing the Raw PhIP-seq Data Timing: several hours`

56	Separately align each sample’s .fastq using the bowtie short read aligner, with the following command:

```
mkdir -p workdir/alns
bowtie -n 3 -l 100 --best --nomaqround --norc -k 1 -p 4 --quiet \
bowtie_index/mylibrary workdir/reads/sample1.fastq.gz \
workdir/alns/sample1.aln
```

CRITICAL STEP: See bowtie’s documentation (bowtie-bio.sourceforge.net) for additional alignment options. With many samples, the commands can be submitted to a batch job scheduler such as LSF, Grid Engine, or SLURM that are commonly available in scientific computing environments.

CRITICAL STEP: This step is computationally expensive and we recommend submitting a job for each file to a batch system on a cluster.

CAUTION: Take care with correctly specifying the path to the bowtie index. If the bowtie index is called index/mylibrary.1.ebwt (along with the additional files), then you should specify index/mylibrary. Note that the backslashes above mean line-continuation.


57	Aggregate each alignment file into a count vector for that sample, using the following command:

```
phip compute-counts -i workdir/alns -o workdir/counts -r path/to/input/counts.tsv
```

The command line flags are: -i, input directory; -o, output directory; -r, reference file containing the input counts for the library. Each count file generated by the command above will contain one column for the input counts (specified with -r) and another column for the counts in that sample (specified with -i). Therefore, this step requires the input counts generated in step 42. Alternatively (and if input counts are not available), aggregated counts from negative control samples can also be used with the -r flag. The input counts are necessary for the statistical model used to compute the enrichment scores. Since this current step is relatively light-weight, it is performed locally.


58	Generate (–log10) p-values from the counts by fitting a Generalized Poisson model and computing a significance score for each pair of count values. Specifically, we model the count value Yi for peptide i as

Yi ~ GeneralizedPoisson(λ(Xi), θ(Xi))

where the functions λ(x) = a x + b and θ(x) = c are fit empirically to the observed data. For each possible input value x, we compute the maximum likelihood estimates for λ, θ using the counts of all peptides with x reads, and regress the λ’s and θ’s against the input counts to get estimated λ and θ as a function of x. The scores can be generated by running the following command:

```
phip compute-pvals -i workdir/counts/sample1.tsv -o workdir/mlxp/sample1.mlxp.tsv
```

Here, -i is a file containing sample counts and -o is the destination file containing the MLXP values (Note: "mlxp" is short for "minus log10 p-val").

CRITICAL STEP: This step is computationally expensive and we recommend submitting a job for each file to a batch system on a cluster.

59	Alternatively, merge the count values into a single tab-delimited file to make it easier to analyze as a single matrix with the following command: .

```
phip merge-columns -i workdir/mlxp -o mlxp.tsv -p 1
```

Here, -i is directory containing MLXP files and -o points to the merged MLXP file containing the full matrix.

This will merge the 2nd column (zero-indexed) of each file together; it assumes the first column is the join key. This step can also be parallelized on a batch scheduler like the alignment step.

60	Load the resulting tab-delimited file into Python or R as a dataframe for further analysis (e.g. the Python pandas library (https://pandas.pydata.org/) or the R tidyverse (https://www.tidyverse.org/)). In python, the command would be:

```
import pandas as pd
df = pd.read_csv(‘mlxp.tsv’, sep=‘\t’, header=0)
```









or


From "VirScan: High-throughput Profiling of Antiviral Antibody Epitopes"

This is the preferred method.




Data analysis

https://os.bio-protocol.org/attached/file/20220629/Supplementary%20materials.docx

https://www.dropbox.com/sh/qvo1t75sgsq7fi8/AAAY-LQEQDrxV6wWF6OJDHPWa?dl=0

Scripts
```
wget -O Analysis_scripts_and_input_files.zip https://ucab945e53b193072c47c959e0d0.dl.dropboxusercontent.com/zip_download_get/BssihrzuYZleo2TpbIP1mmDhr3O42uiTaHHZldsDJQVAFJ5xV-O3OHN8ct5ho-un6hPZiAsT8lQZL2PF3TFtZBej7V4fG6AxUT6lUY_TsvUNLw
```

Notes:
a. In the instructions below, lines of code are bolded. These instructions are for use on a computing cluster using SLURM.
b. Example VirScan data for two serum samples and their technical replicates are provided (Supplementary materials). Data files include a sample legend, fastq files, BAM files, alignment report files, indexed BAM files, counts files, count.combined files (counts summed across four lanes of a Nextseq 500 flow cell), a counts table (count.combined data presented in a table format; summed counts for no-serum controls are provided in the column "input"), a Z-score table (again, summed counts for no-serum controls are present in the column ‘input’), a hits_combined table, and virus scores files.

A. Align sequencing reads to a reference file

1. Use the reference fasta file for the VirScan library ("vir3.fasta") (Supplementary materials) and generate index files with the .ebwt extension. Run the following commands:

```
module load gcc/6.2.0
module load bowtie/1.2.2
bowtie-build vir3.fasta vir3
```

2. Align sequencing reads to the reference file. See "script.align.sh" and edit as needed (Supplementary materials). The output file is a file that ends in ".bam"

Notes:

a. Sequencing reads are typically distributed as fastq files. These fastq files are stored in a subdirectory called "raw.data".
b. In "script.align.sh", "bowtie -3 25" trims 25 nucleotides off the 3’ end of each sequencing read. This is done if sequencing reads are 75 nucleotides in length. The reference file only includes the first 50 nucleotides of each member of the library, so the sequencing reads must be trimmed down to 50 nucleotides to align correctly to the reference.
c. In "script.align.sh", replace "path_to_vir3_reference_fasta_and_index_files" with the appropriate path.

```
./script.align.sh
```

3. Check the alignment report file that ends in ".out"
Note: Typically, >85% of the reads align to the reference file.

4. Index files with the following commands. The output file is a file that ends in ".bai"

```
module load gcc/6.2.0
module load samtools/1.3.1
for i in raw.data/*.bam; do samtools index $i; done
```

5. Count indexes with the following commands. The output is a file that ends in ".count.csv"

```
module load gcc/6.2.0 module load samtools/1.3.1
for i in raw.data/*.bam; do samtools idxstats $i | cut -f 1,3 | sed -e '/^\*\t/d' -e '1 i id\tSAMPLE_ID' |
tr "\\t" "," >${i%.bam}.count.csv; done
```

6. Gzip the counts files with the following command.

```
for i in raw.data/*.csv; do gzip $i; done
```

7. Create a directory called "log_directory" with the following command.

```
mkdir log_directory
```

8. If the same sample is run on two or more lanes of a flow cell and separate files are provided for each flow cell, combine the counts files from the different lanes using the following commands. These commands require the python script "combine_two_lanes.py" to be copied to the folder where you are running the commands (Supplementary materials).

Note: In the code below, the samples were run on four lanes of an Illumina Nextseq 500 flow cell. The suffix of each count file is "L001_R1_001.count.csv.gz" if the count file was from the first lane of the flow cell, "L002_R1_001.count.csv.gz" if the count was from the second lane of the flow cell, etc.

```
module load gcc/6.2.0

module load python

for i in raw.data/*L001_R1_001.count.csv.gz; do python combine_two_lanes.py $i
${i%1_R1_001.count.csv.gz}2_R1_001.count.csv.gz 
${i%1_R1_001.count.csv.gz}1_2_R1_001.count.csv; done

for i in raw.data/*L003_R1_001.count.csv.gz; do python combine_two_lanes.py $i
${i%3_R1_001.count.csv.gz}4_R1_001.count.csv.gz 
${i%3_R1_001.count.csv.gz}3_4_R1_001.count.csv; done

for i in raw.data/*L001_2_R1_001.count.csv; do python combine_two_lanes.py $i
${i%1_2_R1_001.count.csv}3_4_R1_001.count.csv 
${i%1_2_R1_001.count.csv}1_2_3_4_R1_001.count.combined.csv; done
```

9. Gzip the count.combined files with the following command.

```
for i in raw.data/*1_2_3_4_R1.count.combined.csv; do gzip $i; done
```

B. Calculate Z-scores

Note: To perform the Z-score analysis, count.combined files are merged into a table, and columns corresponding with no-serum controls are summed in a column called "input".

1. Edit the R script "Zscore_analysis.R" to include the path to the count.combined table file and the desired
path to the output file, then run the script (Supplementary materials). The packages "mmR_0.1.0" and "virScanR_0.1.0.9000" are required (Supplementary materials).
Note: The file "Zscores_vir3" contains the results after this step (Supplementary materials).
2. A Z-score of at least 3.5 in both technical replicates of a sample is required to call a peptide a "hit".
Note: The file "hits_combined_vir3_3.5_cutoff" contains the results after this step (Supplementary materials).


C. Calculate virus scores

1. Create a directory called "hits". In this directory should be .csv files for each sample with "True" or "False" values for each peptide ID, depending on whether the peptide scored as a hit (Z-score > 3.5) in both technical replicates of a sample or not. These files may be created by splitting each column of the "hits_combined_vir3_3.5_cutoff" file into a separate files (Supplementary materials).
2. Generate virus scores files using the following code:
Note: The "VIR3_clean" file provides the annotations for the oligos" (Supplementary materials). There are 115,753 oligos in the Vir3 library. Some protein fragments are identical in different viruses, and in these case there are multiple rows in the "VIR3_clean" file that correspond to a single oligo. To identify the viral source of a given peptide, look for the row(s) in the VIR3_clean file with the "id" value of the given peptide.

```
for i in hits/*.csv.gz; do python calc_scores_nofilter.py $i VIR3_clean.csv.gz Species 7 >virus_scores_$i; done
```

D. Determining virus seropositivity

1. A sample is determined to be seropositive for a virus if the virus_score > VirScan_viral_threshold and if at least one public epitope from that virus scores as a hit. The file "VirScan_viral_thresholds" contains the thresholds for each virus (Supplementary materials).
Note: Public epitope annotations are available upon request.


