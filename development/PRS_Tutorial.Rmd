#!/usr/bin/env Rscript

args <- commandArgs()
fname <- normalizePath(sub("--file=", "", args[grepl("--file=", args)]))
thisfile <- readLines(fname)
newfname <- paste0(tempdir(), "/", basename(fname))
writeLines(thisfile[-1:-which(thisfile == "q(\"no\")")], newfname)

#Sys.setenv("WORKINGDIRNAME"=dirname(fname))

noext=fs::path_ext_remove(fname)
rmarkdown::render(newfname, output_dir = dirname(fname), output_file = paste0(noext,'.html') )

q("no")

---
title: "PRS Tutorial"
author: "JW"
date: "2025-04-02"
output:
  html_document:
    fig_width: 12
    fig_height: 8
---


From https://choishingwan.github.io/PRS-Tutorial/

There are a few options in the tutorial. This includes my choices.


```{r defaults, include=FALSE}
knitr::opts_knit$set(root.dir = dirname(fname))

knitr::opts_chunk$set(
#	error=TRUE, # my new favorite, will let the script run and create html so you could debug
	comment = '', # Remove comments from the output
#	fig.width = 6, # Set default plot width
#	fig.height = 6, # Set default plot height
	echo = TRUE # Echo code by default
)
```






#	QC of Base Data

##	Obtaining the base data file

The first step in Polygenic Risk Score (PRS) analyses is to generate or obtain the base data (GWAS summary statistics). Ideally these will correspond to the most powerful GWAS results available on the phenotype under study. In this example, we will use GWAS on simulated height. You can download the summary statistic file here


Manually download Height.gwas.txt.gz from ...
https://drive.google.com/file/d/1RWjk49QNZj9zvJHc9X_wyZ51fdy6xQjv/view


##	Reading the base data file

Height.gwas.txt.gz is compressed. To read its content, you can type:

```{bash}
gunzip -c Height.gwas.txt.gz | head
```

which will display the first 10 lines of the file


The Height.gwas.txt.gz file contains the following columns:

CHR	BP	SNP	A1	A2	N	SE	P	OR	INFO	MAF
1	756604	rs3131962	A	G	388028	0.00301666	0.483171	0.997886915712657	0.890557941364774	0.369389592764921
1	768448	rs12562034	A	G	388028	0.00329472	0.834808	1.00068731609353	0.895893511351165	0.336845754096289
1	779322	rs4040617	G	A	388028	0.00303344	0.42897	0.997603556067569	0.897508290615237	0.377368010940814
The column headers correspond to the following:

CHR: The chromosome in which the SNP resides
BP: Chromosomal co-ordinate of the SNP
SNP: SNP ID, usually in the form of rs-ID
A1: The effect allele of the SNP
A2: The non-effect allele of the SNP
N: Number of samples used to obtain the effect size estimate
SE: The standard error (SE) of the effect size esimate
P: The P-value of association between the SNP genotypes and the base phenotype
OR: The effect size estimate of the SNP, if the outcome is binary/case-control. If the outcome is continuous or treated as continuous then this will usually be BETA
INFO: The imputation information score
MAF: The minor allele frequency (MAF) of the SNP

##	QC checklist: Base data

Below we perform QC on these base data according to the 'QC checklist' in our guide paper, which we recommend that users follow while going through this tutorial and when performing PRS analyses:

### Heritability check

We recommend that PRS analyses are performed on base data with a chip-heritability estimate `h 2 s n p > 0.05`. The chip-heritability of a GWAS can be estimated using e.g. LD Score Regression (LDSC). Our height GWAS data are simulated to have a chip-heritability much greater than 0.05 and so we can move on to the next QC step.

### Effect allele

It is important to know which allele is the effect allele and which is the non-effect allele for PRS association results to be in the correct direction.

Important

Some GWAS results files do not make clear which allele is the effect allele and which is the non-effect allele. If the incorrect assumption is made in computing the PRS, then the effect of the PRS in the target data will be in the wrong direction.

To avoid misleading conclusions the effect allele from the base (GWAS) data must be known.

### File transfer

A common problem is that the downloaded base data file can be corrupted during download, which can cause PRS software to crash or to produce errors in results. However, a md5sum hash is generally included in files so that file integrity can be checked. The following command performs this md5sum check:


```{bash}
md5sum Height.gwas.txt.gz
```

if the file is intact, then md5sum generates a string of characters, which in this case should be: a2b15fb6a2bbbe7ef49f67959b43b160. If a different string is generated, then the file is corrupted.

### Genome build

The height summary statistic are on the same genome build as the target data that we will be using. You must check that your base and target data are on the same genome build, and if they are not then use a tool such as LiftOver to make the builds consistent across the data sets.

### Standard GWAS QC

As described in the paper, both the base and target data should be subjected to the standard stringent QC steps performed in GWAS. If the base data have been obtained as summary statistics from a public source, then the typical QC steps that you will be able to perform on them are to filter the SNPs according to INFO score and MAF. SNPs with low minor allele frequency (MAF) or imputation information score (INFO) are more likely to generate false positive results due to their lower statistical power (and higher probability of genotyping errors in the case of low MAF). Therefore, SNPs with low MAF and INFO are typically removed before performing downstream analyses. We recommend removing SNPs with MAF < 1% and INFO < 0.8 (with very large base sample sizes these thresholds could be reduced if sensitivity checks indicate reliable results). These SNP filters can be achieved using the following code:


```{bash}
gunzip -c Height.gwas.txt.gz |\
awk 'NR==1 || ($11 > 0.01) && ($10 > 0.8) {print}' |\
gzip  > Height.gz
```




Using R with data.table
The bash code above does the following:

Decompresses and reads the Height.gwas.txt.gz file

Prints the header line (NR==1)

Prints any line with MAF above 0.01 (\$11 because the eleventh column of the file contains the MAF information)

Prints any line with INFO above 0.8 (\$10 because the tenth column of the file contains the INFO information)

Compresses and writes the results to Height.gz

### Mismatching SNPs

SNPs that have mismatching alleles reported in the base and target data are either resolvable by "strand-flipping" the alleles to their complementary alleles in e.g. the target data, such as for a SNP with A/C in the base data and G/T in the target, or non-resolvable, such as for a SNP with C/G in the base and C/T in the target. Most polygenic score software perform strand-flipping automatically for SNPs that are resolvable, and remove non-resolvable mismatching SNPs.

Since we need the target data to know which SNPs have mismatching alleles, we will perform this strand-flipping in the target data.

### Duplicate SNPs

If an error has occurred in the generation of the base data then there may be duplicated SNPs in the base data file. Most PRS software do not allow duplicated SNPs in the base data input and thus they should be removed, using a command such as the one below:


```{bash}
gunzip -c Height.gz |\
awk '{seen[$3]++; if(seen[$3]==1){ print}}' |\
gzip - > Height.nodup.gz
```

The above command does the following:

Decompresses and reads the Height.gz file
Count number of time SNP ID was observed, assuming the third column contian the SNP ID (`seen[$3]++`). If this is the first time seeing this SNP ID, print it.
Compresses and writes the results to Height.nodup.gz
How many duplicated SNPs are there?
There are a total of 2 duplicated SNPs

### Ambiguous SNPs


If the base and target data were generated using different genotyping chips and the chromosome strand (+/-) that was used for either is unknown, then it is not possible to pair-up the alleles of ambiguous SNPs (i.e. those with complementary alleles, either C/G or A/T SNPs) across the data sets, because it will be unknown whether the base and target data are referring to the same allele or not. While allele frequencies could be used to infer which alleles are on the same strand, the accuracy of this could be low for SNPs with MAF close to 50% or when the base and target data are from different populations. Therefore, we recommend removing all ambiguous SNPs to avoid introducing this potential source of systematic error.

Ambiguous SNPs can be removed in the base data and then there will be no such SNPs in the subsequent analyses, since analyses are performed only on SNPs that overlap between the base and target data.

Nonambiguous SNPs can be retained using the following:



```{bash}
gunzip -c Height.nodup.gz |\
awk '!( ($4=="A" && $5=="T") || \
        ($4=="T" && $5=="A") || \
        ($4=="G" && $5=="C") || \
        ($4=="C" && $5=="G")) {print}' |\
    gzip > Height.QC.gz
```

How many non-ambiguous SNPs were there?
There are 499,617 non-ambiguous SNPs




### Sex chromosomes

Sometimes sample mislabelling can occur, which may lead to invalid results. One indication of a mislabelled sample is a difference between reported sex and that indicated by the sex chromosomes. While this may be due to a difference in sex and gender identity, it could also reflect mislabeling of samples or misreporting and, thus, individuals in which there is a mismatch between biological and reported sex are typically removed. See the Target Data section in which a sex-check is performed.

### Sample overlap

Since the target data were simulated there are no overlapping samples between the base and target data here (see the relevant section of the paper for discussion of the importance of avoiding sample overlap).

### Relatedness

Closely related individuals within and between the base and the target data may lead to overfitted results, limiting the generalizability of the results (see the relevant sections of the paper). Relatedness within the target data is tested in the Target Data section.

The Height.QC.gz base data are now ready for using in downstream analyses.





#	QC of Target Data

##	Obtaining the target data

Target data consist of individual-level genotype-phenotype data, usually generated within your lab/department/collaboration. For this tutorial, we have simulated some genotype-phenotype data using the 1000 Genomes Project European samples. You can download the data here

Manually download EUR.zip from 
https://drive.google.com/file/d/1uhJR_3sn7RA8U5iYQbcmTp6vFdQiF4F2/view
and then unzip





##	QC checklist: Target data

Below are the QC steps that comprise the QC checklist for the target data.

### Sample size

We recommend that users only perform PRS analyses on target data of at least 100 individuals. The sample size of our target data here is 503 individuals.

### File transfer

Usually we do not need to download and transfer the target data file because it is typically generated locally. However, the file should contain an md5sum code in case we send the data file to collaborators who may want to confirm that the file has not changed during the transfer.

What is the md5sum code for each of the target files?
File	md5sum
EUR.bed	98bcef133f683b1272d3ea5f97742e0e
EUR.bim	6b286002904880055a9c94e01522f059
EUR.cov	85ed18288c708e095385418517e9c3bd
EUR.fam	e7b856f0c7bcaffc8405926d08386e97
EUR.height	dd445ce969a81cded20da5c88b82d4df

### Genome build

As stated in the base data section, the genome build for our base and target data is the same, as it should be.

### Standard GWAS QC

The target data must be quality controlled to at least the standards implemented in GWAS studies, e.g. removing SNPs with low genotyping rate, low minor allele frequency, out of Hardy-Weinberg Equilibrium, removing individuals with low genotyping rate (see Marees et al).

The following plink command applies some of these QC metrics to the target data:

```{bash plink01}
module load plink
plink \
    --bfile EUR \
    --maf 0.01 \
    --hwe 1e-6 \
    --geno 0.01 \
    --mind 0.01 \
    --write-snplist \
    --make-just-fam \
    --out EUR.QC
```




Each of the parameters corresponds to the following

Parameter	Value	Description
bfile	EUR	Informs plink that the input genotype files should have a prefix of EUR
maf	0.01	Removes all SNPs with minor allele frequency less than 0.01. Genotyping errors typically have a larger influence on SNPs with low MAF. Studies with large sample sizes could apply a lower MAF threshold
hwe	1e-6	Removes SNPs with low P-value from the Hardy-Weinberg Equilibrium Fisher's exact or chi-squared test. SNPs with significant P-values from the HWE test are more likely affected by genotyping error or the effects of natural selection. Filtering should be performed on the control samples to avoid filtering SNPs that are causal (under selection in cases). When phenotype information is included, plink will automatically perform the filtering in the controls.
geno	0.01	Excludes SNPs that are missing in a high fraction of subjects. A two-stage filtering process is usually performed (see Marees et al).
mind	0.01	Excludes individuals who have a high rate of genotype missingness, since this may indicate problems in the DNA sample or processing. (see Marees et al for more details).
make-just-fam	-	Informs plink to only generate the QC'ed sample name to avoid generating the .bed file.
write-snplist	-	Informs plink to only generate the QC'ed SNP list to avoid generating the .bed file.
out	EUR.QC	Informs plink that all output should have a prefix of EUR.QC

How many SNPs and samples were filtered?
14 samples were removed due to a high rate of genotype missingness
5,353 SNP were removed due to missing genotype data
944 SNPs were removed due to being out of Hardy-Weinberg Equilibrium
5,061 SNPs were removed due to low minor allele frequency
Note

Normally, we can generate a new genotype file using the new sample list. However, this will use up a lot of storage space. Using plink's --extract, --exclude, --keep, --remove, --make-just-fam and --write-snplist functions, we can work solely on the list of samples and SNPs without duplicating the genotype file, reducing the storage space usage.

Very high or low heterozygosity rates in individuals could be due to DNA contamination or to high levels of inbreeding. Therefore, samples with extreme heterozygosity are typically removed prior to downstream analyses.

First, we perform pruning to remove highly correlated SNPs:





```{bash plink02}
module load plink
plink \
    --bfile EUR \
    --keep EUR.QC.fam \
    --extract EUR.QC.snplist \
    --indep-pairwise 200 50 0.25 \
    --out EUR.QC
```



Each of the parameters corresponds to the following

Parameter	Value	Description
bfile	EUR	Informs plink that the input genotype files should have a prefix of EUR
keep	EUR.QC.fam	Informs plink that we only want to use samples in EUR.QC.fam in the analysis
extract	EUR.QC.snplist	Informs plink that we only want to use SNPs in EUR.QC.snplist in the analysis
indep-pairwise	200 50 0.25	Informs plink that we wish to perform pruning with a window size of 200 variants, sliding across the genome with step size of 50 variants at a time, and filter out any SNPs with LD `r 2` higher than 0.25
out	EUR.QC	Informs plink that all output should have a prefix of EUR.QC
This will generate two files 1) EUR.QC.prune.in and 2) EUR.QC.prune.out. All SNPs within EUR.QC.prune.in have a pairwise 
`r 2 < 0.25`.

Heterozygosity rates can then be computed using plink:




```{bash plink03}
module load plink
plink \
    --bfile EUR \
    --extract EUR.QC.prune.in \
    --keep EUR.QC.fam \
    --het \
    --out EUR.QC
```

This will generate the EUR.QC.het file, which contains F coefficient estimates for assessing heterozygosity. We will remove individuals with F coefficients that are more than 3 standard deviation (SD) units from the mean, which can be performed using the following R command (assuming that you have R downloaded, then you can open an R session by typing R in your terminal):

With data.table
```{r qc_het}
library(data.table)
# Read in file
dat <- fread("EUR.QC.het")
# Get samples with F coefficient within 3 SD of the population mean
valid <- dat[F<=mean(F)+3*sd(F) & F>=mean(F)-3*sd(F)]
# print FID and IID for valid samples
fwrite(valid[,c("FID","IID")], "EUR.valid.sample", sep="\t")
```

How many samples were excluded due to high heterozygosity rate?
2 samples were excluded

### Ambiguous SNPs

These were removed during the base data QC.

### Mismatching SNPs

SNPs that have mismatching alleles reported in the base and target data may be resolvable by strand-flipping the alleles to their complementary alleles in e.g. the target data, such as for a SNP with A/C in the base data and G/T in the target. This can be achieved with the following steps:

Note

Most PRS software will perform strand-flipping automatically, thus this step is usually not required.

1. Load the bim file, the summary statistic and the QC SNP list into R


With data.table and magrittr
```{r mismatchingsnps}
# magrittr allow us to do piping, which help to reduce the
# amount of intermediate data types
library(data.table)
library(magrittr)
# Read in bim file
bim <- fread("EUR.bim") %>%
    # Note: . represents the output from previous step
    # The syntax here means, setnames of the data read from
    # the bim file, and replace the original column names by
    # the new names
    setnames(., colnames(.), c("CHR", "SNP", "CM", "BP", "B.A1", "B.A2")) %>%
    # And immediately change the alleles to upper cases
    .[,c("B.A1","B.A2"):=list(toupper(B.A1), toupper(B.A2))]
# Read in summary statistic data (require data.table v1.12.0+)
height <- fread("Height.QC.gz") %>%
    # And immediately change the alleles to upper cases
    .[,c("A1","A2"):=list(toupper(A1), toupper(A2))]
# Read in QCed SNPs
qc <- fread("EUR.QC.snplist", header=F)
```

2. Identify SNPs that require strand flipping


```{r merge_summary}
# Merge summary statistic with target
info <- merge(bim, height, by=c("SNP", "CHR", "BP")) %>%
    # And filter out QCed SNPs
    .[SNP %in% qc[,V1]]

# Function for calculating the complementary allele
complement <- function(x){
    switch (x,
        "A" = "T",
        "C" = "G",
        "T" = "A",
        "G" = "C",
        return(NA)
    )
}
# Get SNPs that have the same alleles across base and target
info.match <- info[A1 == B.A1 & A2 == B.A2, SNP]
# Identify SNPs that are complementary between base and target
com.snps <- info[sapply(B.A1, complement) == A1 &
                    sapply(B.A2, complement) == A2, SNP]
# Now update the bim file
bim[SNP %in% com.snps, c("B.A1", "B.A2") :=
        list(sapply(B.A1, complement),
            sapply(B.A2, complement))]
```


3. Identify SNPs that require recoding in the target (to ensure the coding allele in the target data is the effective allele in the base summary statistic)




```{r recode_snps}
# identify SNPs that need recoding
recode.snps <- info[B.A1==A2 & B.A2==A1, SNP]
# Update the bim file
bim[SNP %in% recode.snps, c("B.A1", "B.A2") :=
        list(B.A2, B.A1)]

# identify SNPs that need recoding & complement
com.recode <- info[sapply(B.A1, complement) == A2 &
                    sapply(B.A2, complement) == A1, SNP]
# Now update the bim file
bim[SNP %in% com.recode, c("B.A1", "B.A2") :=
        list(sapply(B.A2, complement),
            sapply(B.A1, complement))]
# Write the updated bim file
fwrite(bim[,c("SNP", "B.A1")], "EUR.a1", col.names=F, sep="\t")
```


4. Identify SNPs that have different allele in base and target (usually due to difference in genome build or Indel)




```{r write_mismatches}
mismatch <- bim[!(SNP %in% info.match |
                    SNP %in% com.snps |
                    SNP %in% recode.snps |
                    SNP %in% com.recode), SNP]
write.table(mismatch, "EUR.mismatch", quote=F, row.names=F, col.names=F)
```


We can then use the EUR.a1 file to update the A1 alleles

### Duplicate SNPs

Make sure to remove any duplicate SNPs in your target data (these target data were simulated and so include no duplicated SNPs).

### Sex chromosomes

Sometimes sample mislabelling can occur, which may lead to invalid results. One indication of a mislabelled sample is a difference between reported sex and that indicated by the sex chromosomes. While this may be due to a difference in sex and gender identity, it could also reflect mislabeling of samples or misreporting and, thus, individuals in which there is a mismatch between biological and reported sex are typically removed. A sex check can be performed in PLINK, in which individuals are called as females if their X chromosome homozygosity estimate (F statistic) is < 0.2 and as males if the estimate is > 0.8.

Before performing a sex check, pruning should be performed (see here). A sex check can then easily be conducted using plink


```{bash plink04}
module load plink

plink \
    --bfile EUR \
    --extract EUR.QC.prune.in \
    --keep EUR.valid.sample \
    --check-sex \
    --out EUR.QC
```

This will generate a file called EUR.QC.sexcheck containing the F-statistics for each individual. Individuals are typically called as being biologically male if the F-statistic is > 0.8 and biologically female if F < 0.2.




```{r EUR_valid_sample}
library(data.table)
# Read in file
valid <- fread("EUR.valid.sample")
dat <- fread("EUR.QC.sexcheck")[FID%in%valid$FID]
fwrite(dat[STATUS=="OK",c("FID","IID")], "EUR.QC.valid", sep="\t")
```

How many samples were excluded due mismatched Sex information?
4 samples were excluded

### Sample overlap

Since the target data were simulated there are no overlapping samples between the base and target data here (see the relevant section of the paper for discussion of the importance of avoiding sample overlap).

### Relatedness

Closely related individuals in the target data may lead to overfitted results, limiting the generalisability of the results.

Before calculating the relatedness, pruning should be performed (see here). Individuals that have a first or second degree relative in the sample ( `^ π > 0.125`) can be removed with the following command:


```{bash plink05}
module load plink
plink \
    --bfile EUR \
    --extract EUR.QC.prune.in \
    --keep EUR.QC.valid \
    --rel-cutoff 0.125 \
    --out EUR.QC
```


How many related samples were excluded?
0 samples were excluded

Note

A greedy algorithm is used to remove closely related individuals in a way that optimizes the size of the sample retained. However, the algorithm is dependent on the random seed used, which can generate different results. Therefore, to reproduce the same result, you will need to specify the same random seed.

PLINK's algorithm for removing related individuals does not account for the phenotype under study. To minimize the removal of cases of a disease, the following algorithm can be used instead: GreedyRelated.

##	Generate final QC'ed target data file

After performing the full analysis, you can generate a QC'ed data set with the following command:



```{bash plink06}
module load plink
plink \
    --bfile EUR \
    --make-bed \
    --keep EUR.QC.rel.id \
    --out EUR.QC \
    --extract EUR.QC.snplist \
    --exclude EUR.mismatch \
    --a1-allele EUR.a1
```


Each of the parameters corresponds to the following

Parameter	Value	Description
bfile	EUR	Informs plink that the input genotype files should have a prefix of EUR
keep	EUR.QC.rel.id	Informs plink that we only want to keep samples in EUR.QC.rel.id
extract	EUR.QC.snplist	Informs plink that we only want to use SNPs in EUR.QC.snplist in the analysis
exclude	EUR.mismatch	Informs plink that we wish to remove any SNPs in EUR.mismatch
a1-allele	EUR.a1	Fix all A1 alleles to those specified in EUR.a1
out	EUR.QC	Informs plink that all output should have a prefix of EUR.QC



#	Calculating and Analysing PRS

##	Background

In this section of the tutorial you will use four different software programs to compute PRS from the base and target data that you QC'ed in the previous two sections.

The programs are

PLINK
PRSice-2
LDPred-2
lassosum


#	Background

On this page, you will compute PRS using the popular genetic analyses tool plink - while plink is not a dedicated PRS software, you can perform every required steps of the C+T approach with plink. This multi-step process is a good way to learn the processes involved in computing PRS, which are typically performed automatically by PRS software.

##	Required Data

In the previous sections, we have generated the following files:

File Name	Description
Height.QC.gz	The post-QCed summary statistic
EUR.QC.bed	The genotype file after performing some basic filtering
EUR.QC.bim	This file contains the SNPs that passed the basic filtering
EUR.QC.fam	This file contains the samples that passed the basic filtering
EUR.height	This file contains the phenotype of the samples
EUR.cov	This file contains the covariates of the samples

##	Update Effect Size

When the effect size relates to disease risk and is thus given as an odds ratio (OR), rather than BETA (for continuous traits), then the PRS is computed as a product of ORs. To simplify this calculation, we take the natural logarithm of the OR so that the PRS can be computed using summation instead (which can be back-transformed afterwards). We can obtain the transformed summary statistics with R:


```{r Height_QC}
library(data.table)
dat <- fread("Height.QC.gz")
fwrite(dat[,BETA:=log(OR)], "Height.QC.Transformed", sep="\t")
```


##	Clumping

Linkage disequilibrium, which corresponds to the correlation between the genotypes of genetic variants across the genome, makes identifying the contribution from causal independent genetic variants extremely challenging. One way of approximately capturing the right level of causal signal is to perform clumping, which removes SNPs in ways that only weakly correlated SNPs are retained but preferentially retaining the SNPs most associated with the phenotype under study. Clumping can be performed using the following command in plink:



```{bash plink07}
module load plink
plink \
    --bfile EUR.QC \
    --clump-p1 1 \
    --clump-r2 0.1 \
    --clump-kb 250 \
    --clump Height.QC.Transformed \
    --clump-snp-field SNP \
    --clump-field P \
    --out EUR
```

Each of the new parameters corresponds to the following

Parameter	Value	Description
clump-p1	1	P-value threshold for a SNP to be included as an index SNP. 1 is selected such that all SNPs are include for clumping
clump-r2	0.1	SNPs having ` r 2` higher than 0.1 with the index SNPs will be removed
clump-kb	250	SNPs within 250k of the index SNP are considered for clumping
clump	Height.QC.Transformed	Base data (summary statistic) file containing the P-value information
clump-snp-field	SNP	Specifies that the column SNP contains the SNP IDs
clump-field	P	Specifies that the column P contains the P-value information
A more detailed description of the clumping process can be found here

Note

The `r 2` values computed by --clump are based on maximum likelihood haplotype frequency estimates

This will generate EUR.clumped, containing the index SNPs after clumping is performed. We can extract the index SNP ID by performing the following command:


```{bash}
awk 'NR!=1{print $3}' EUR.clumped > EUR.valid.snp
```


\$3 because the third column contains the SNP ID

Note

If your target data are small (e.g. N < 500) then you can use the 1000 Genomes Project samples for the LD calculation. Make sure to use the population that most closely reflects represents the base sample.

##	Generate PRS

plink provides a convenient function --score and --q-score-range for calculating polygenic scores.

We will need three files:

The base data file: Height.QC.Transformed
A file containing SNP IDs and their corresponding P-values (\$3 because SNP ID is located in the third column; \$8 because the P-value is located in the eighth column)



```{bash}
awk '{print $3,$8}' Height.QC.Transformed > SNP.pvalue
```

A file containing the different P-value thresholds for inclusion of SNPs in the PRS. Here calculate PRS corresponding to a few thresholds for illustration purposes:


```{bash}
echo "0.001 0 0.001" > range_list
echo "0.05 0 0.05" >> range_list
echo "0.1 0 0.1" >> range_list
echo "0.2 0 0.2" >> range_list
echo "0.3 0 0.3" >> range_list
echo "0.4 0 0.4" >> range_list
echo "0.5 0 0.5" >> range_list
```

The format of the range_list file should be as follows:
Name of Threshold	Lower bound	Upper Bound
Note

The threshold boundaries are inclusive. For example, for the 0.05 threshold, we include all SNPs with P-value from 0 to 0.05, including any SNPs with P-value equal to 0.05.

We can then calculate the PRS with the following plink command:





```{bash plink08}
module load plink
plink \
    --bfile EUR.QC \
    --score Height.QC.Transformed 3 4 12 header \
    --q-score-range range_list SNP.pvalue \
    --extract EUR.valid.snp \
    --out EUR
```



The meaning of the new parameters are as follows:
Paramter	Value	Description
score	Height.QC.Transformed 3 4 12 header	We read from the Height.QC.Transformed file, assuming that the 3st column is the SNP ID; 4th column is the effective allele information; the 12th column is the effect size estimate; and that the file contains a header
q-score-range	range_list SNP.pvalue	We want to calculate PRS based on the thresholds defined in range_list, where the threshold values (P-values) were stored in SNP.pvalue
The above command and range_list will generate 7 files:

EUR.0.5.profile
EUR.0.4.profile
EUR.0.3.profile
EUR.0.2.profile
EUR.0.1.profile
EUR.0.05.profile
EUR.0.001.profile
Note

The default formula for PRS calculation in PLINK is:

`P R S j = ∑ N i S i ∗ G i j P ∗ M j`
where the effect size of SNP 
`i` is `S i`
; the number of effect alleles observed in sample 
`j` is `G i j` ; the ploidy of the sample is 
`P` (is generally 2 for humans); the total number of SNPs included in the PRS is `N` ; and the number of non-missing SNPs observed in sample `j` is `M j` . If the sample has a missing genotype for SNP ` i` , then the population minor allele frequency multiplied by the ploidy (` M A F i ∗ P`) is used instead of `G i j` .

##	Accounting for Population Stratification

Population structure is the principal source of confounding in GWAS and is usually accounted for by incorporating principal components (PCs) as covariates. We can incorporate PCs into our PRS analysis to account for population stratification.

Again, we can calculate the PCs using plink:




```{bash plink09}
module load plink
# First, we need to perform prunning
plink \
    --bfile EUR.QC \
    --indep-pairwise 200 50 0.25 \
    --out EUR
# Then we calculate the first 6 PCs
plink \
    --bfile EUR.QC \
    --extract EUR.prune.in \
    --pca 6 \
    --out EUR
```


Note

One way to select the appropriate number of PCs is to perform GWAS on the phenotype under study with different numbers of PCs. LDSC analysis can then be performed on the set of GWAS summary statistics and the GWAS that used the number of PCs that gave an LDSC intercept closest to 1 should correspond to that for which population structure was most accurately controlled for.

Here the PCs have been stored in the EUR.eigenvec file and can be used as covariates in the regression model to account for population stratification.

Important

If the base and target samples are collected from different worldwide populations then the results from the PRS analysis may be biased (see Section 3.4 of our paper).

##Finding the "best-fit" PRS

The P-value threshold that provides the "best-fit" PRS under the C+T method is usually unknown. To approximate the "best-fit" PRS, we can perform a regression between PRS calculated at a range of P-value thresholds and then select the PRS that explains the highest phenotypic variance (please see Section 4.6 of our paper on overfitting issues). This can be achieved using R as follows:





```{r find_best_fit}
library(data.table)
library(magrittr)
p.threshold <- c(0.001,0.05,0.1,0.2,0.3,0.4,0.5)
phenotype <- fread("EUR.height")
pcs <- fread("EUR.eigenvec", header=F) %>%
    setnames(., colnames(.), c("FID", "IID", paste0("PC",1:6)) )
covariate <- fread("EUR.cov")
pheno <- merge(phenotype, covariate) %>%
        merge(., pcs)
null.r2 <- summary(lm(Height~., data=pheno[,-c("FID", "IID")]))$r.squared
prs.result <- NULL
for(i in p.threshold){
    pheno.prs <- paste0("EUR.", i, ".profile") %>%
        fread(.) %>%
        .[,c("FID", "IID", "SCORE")] %>%
        merge(., pheno, by=c("FID", "IID"))

    model <- lm(Height~., data=pheno.prs[,-c("FID","IID")]) %>%
            summary
    model.r2 <- model$r.squared
    prs.r2 <- model.r2-null.r2
    prs.coef <- model$coeff["SCORE",]
    prs.result %<>% rbind(.,
        data.frame(Threshold=i, R2=prs.r2,
                    P=as.numeric(prs.coef[4]),
                    BETA=as.numeric(prs.coef[1]),
                    SE=as.numeric(prs.coef[2])))
}
print(prs.result[which.max(prs.result$R2),])
```


Which P-value threshold generates the "best-fit" PRS?
0.3

How much phenotypic variation does the "best-fit" PRS explain?
0.1612372




#	Background

PRSice-2 is one of the dedicated PRS programs which automates many of the steps from the previous page that used a sequence of PLINK functions (plus some QC steps). On this page you will run a PRS analysis using PRSice-2, which implements the standard C+T method.

##	Obtaining PRSice-2

PRSice-2 can be downloaded from:

Operating System	Link
Linux 64-bit	v2.3.3
OS X 64-bit	v2.3.3
and can be directly used after extracting the file.

In this tutorial, you will only need PRSice.R and PRSice_XXX where XXX is the operation system

##	Required Data

This analysis assumes that you have the following files (or you can download it from here):

File Name	Description
Height.QC.gz	The post QC base data file. While PRSice-2 can automatically apply most filtering on the base file, it cannot remove duplicated SNPs
EUR.QC.bed	This file contains the genotype data that passed the QC steps
EUR.QC.bim	This file contains the list of SNPs that passed the QC steps
EUR.QC.fam	This file contains the samples that passed the QC steps
EUR.height	This file contains the phenotype data of the samples
EUR.cov	This file contains the covariates of the samples
EUR.eigenvec	This file contains the principal components (PCs) of the samples
Running PRS analysis
To run PRSice-2 we need a single covariate file, and therefore our covariate file and PCs file should be combined. This can be done with R as follows:



```{r PRS_EUR_cov}
library(data.table)
covariate <- fread("EUR.cov")
pcs <- fread("EUR.eigenvec", header=F)
colnames(pcs) <- c("FID","IID", paste0("PC",1:6))
cov <- merge(covariate, pcs)
fwrite(cov,"EUR.covariate", sep="\t")
```


which generates EUR.covariate.

PRSice-2 can then be run to obtain the PRS results as follows:


```{bash get_PRSice}
#wget https://github.com/choishingwan/PRSice/releases/download/2.3.3/PRSice_linux.zip
#unzip PRSice_linux.zip
```


```{bash run_PRSice}
\rm EUR.QC.bk

Rscript PRSice.R \
    --prsice PRSice_linux \
    --base Height.QC.gz \
    --target EUR.QC \
    --binary-target F \
    --pheno EUR.height \
    --cov EUR.covariate \
    --base-maf MAF:0.01 \
    --base-info INFO:0.8 \
    --stat OR \
    --or \
    --out EUR
```



The meaning of the parameters are as follow:

Paramter	Value	Description
prsice	PRSice_xxx	Informs PRSice.R that the location of the PRSice binary
base	Height.QC.gz	Informs PRSice that the name of the GWAS summary statistic
target	EUR.QC	Informs PRSice that the input genotype files should have a prefix of EUR.QC
binary-target	F	Indicate if the phenotype of interest is a binary trait. F for no
pheno	EUR.height	Provide PRSice with the phenotype file
cov	EUR.covariate	Provide PRSice with the covariate file
base-maf	MAF:0.01	Filter out SNPs with MAF < 0.01 in the GWAS summary statistics, using information in the MAF column
base-info	INFO:0.8	Filter out SNPs with INFO < 0.8 in the GWAS summary statistics, using information in the INFO column
stat	OR	Column name of the column containing the effect size
or	-	Inform PRSice that the effect size is an Odd Ratio
out	EUR	Informs PRSice that all output should have a prefix of EUR
This will automatically perform "high-resolution scoring" and generate the "best-fit" PRS (in EUR.best), with associated plots of the results. Users should read Section 4.6 of our paper to learn more about issues relating to overfitting in PRS analyses.

Which P-value threshold generates the "best-fit" PRS?
0.3

How much phenotypic variation does the "best-fit" PRS explain?
0.161237




#	Background

LDpred-2 is one of the dedicated PRS programs which is an R package that uses a Bayesian approach to polygenic risk scoring.

##	Installing LDpred-2

Note

The script used here is based on LDpred 2 implemented under bigsnpr version 1.4.7

Note

For more details, please refer to LDpred 2's homepage

You can install LDpred and its dependencies in R with the following command:

```{r install_bigsnpr}
#	install.packages("remotes")
#	library(remotes)
#	remotes::install_github("https://github.com/privefl/bigsnpr.git")
```




##	Required Data

We assume that you have the following files (or you can download it from here):

File Name	Description
Height.QC.gz	The post-QCed summary statistic
EUR.QC.bed	The genotype file after performing some basic filtering
EUR.QC.bim	This file contains the SNPs that passed the basic filtering
EUR.QC.fam	This file contains the samples that passed the basic filtering
EUR.height	This file contains the phenotype of the samples
EUR.cov	This file contains the covariates of the samples
EUR.eigenvec	This file contains the PCs of the samples
Warning

While we do provide a rough guide on how to perform LDpred on bed files separated into individual chromosomes, this script is untested and extra caution is required

##	0. Prepare workspace
On some server, you might need to first use the following code in order to run LDpred with multi-thread




```{r bigsnpr}
library(bigsnpr)
options(bigstatsr.check.parallel.blas = FALSE)
options(default.nproc.blas = NULL)
```

##	1. Read in the phenotype and covariate files

```{r read_phenotype}
library(data.table)
library(magrittr)
phenotype <- fread("EUR.height")
covariate <- fread("EUR.cov")
pcs <- fread("EUR.eigenvec")
# rename columns
colnames(pcs) <- c("FID","IID", paste0("PC",1:6))
# generate required table
pheno <- merge(phenotype, covariate) %>%
    merge(., pcs)
```

##	2. Obtain HapMap3 SNPs

LDpred2 authors recommend restricting the analysis to only the HapMap3 SNPs



This likes to timeout or only partially download so trying to make it only run once.
Pain in the butt. Trying to download manually.

```{r getHapMap3}
runonce::download_file(
	"https://ndownloader.figshare.com/files/25503788",
	fname = "map_hm3_ldpred2.rds", dir=getwd())

info <- readRDS("map_hm3_ldpred2.rds")
```

##	3. Load and transform the summary statistic file

```{r read_height_qc}
# Read in the summary statistic file
sumstats <- bigreadr::fread2("Height.QC.gz")
# LDpred 2 require the header to follow the exact naming
names(sumstats) <-
    c("chr",
    "pos",
    "rsid",
    "a1",
    "a0",
    "n_eff",
    "beta_se",
    "p",
    "OR",
    "INFO",
    "MAF")
# Transform the OR into log(OR)
sumstats$beta <- log(sumstats$OR)
# Filter out hapmap SNPs
sumstats <- sumstats[sumstats$rsid%in% info$rsid,]
```

##	4. Calculate the LD matrix

```{r calculate_LD}
# Get maximum amount of cores
NCORES <- nb_cores()
# Open a temporary file
tmp <- tempfile(tmpdir = "tmp-data")
on.exit(file.remove(paste0(tmp, ".sbk")), add = TRUE)
# Initialize variables for storing the LD score and LD matrix
corr <- NULL
ld <- NULL
# We want to know the ordering of samples in the bed file
fam.order <- NULL
# preprocess the bed file (only need to do once for each data set)
snp_readBed("EUR.QC.bed")
# now attach the genotype object
obj.bigSNP <- snp_attach("EUR.QC.rds")
# extract the SNP information from the genotype
map <- obj.bigSNP$map[-3]
names(map) <- c("chr", "rsid", "pos", "a1", "a0")
# perform SNP matching
info_snp <- snp_match(sumstats, map)
# Assign the genotype to a variable for easier downstream analysis
genotype <- obj.bigSNP$genotypes
# Rename the data structures
CHR <- map$chr
POS <- map$pos
# get the CM information from 1000 Genome
# will download the 1000G file to the current directory (".")
POS2 <- snp_asGeneticPos(CHR, POS, dir = ".")
# calculate LD
for (chr in 1:22) {
    # Extract SNPs that are included in the chromosome
    ind.chr <- which(info_snp$chr == chr)
    ind.chr2 <- info_snp$`_NUM_ID_`[ind.chr]
    # Calculate the LD
    corr0 <- snp_cor(
            genotype,
            ind.col = ind.chr2,
            ncores = NCORES,
            infos.pos = POS2[ind.chr2],
            size = 3 / 1000
        )
    if (chr == 1) {
        ld <- Matrix::colSums(corr0^2)
        corr <- as_SFBM(corr0, tmp)
    } else {
        ld <- c(ld, Matrix::colSums(corr0^2))
        corr$add_columns(corr0, nrow(corr))
    }
}
# We assume the fam order is the same across different chromosomes
fam.order <- as.data.table(obj.bigSNP$fam)
# Rename fam order
setnames(fam.order,
        c("family.ID", "sample.ID"),
        c("FID", "IID"))
```

##	5. Perform LD score regression


```{r LD_score_regression}
df_beta <- info_snp[,c("beta", "beta_se", "n_eff", "_NUM_ID_")]
ldsc <- snp_ldsc(   ld,
                    length(ld),
                    chi2 = (df_beta$beta / df_beta$beta_se)^2,
                    sample_size = df_beta$n_eff,
                    blocks = NULL)
h2_est <- ldsc[["h2"]]
```

##	6. Calculate the null R2


```{r calculate_null_R2}
# Reformat the phenotype file such that y is of the same order as the
# sample ordering in the genotype file
y <- pheno[fam.order, on = c("FID", "IID")]
# Calculate the null R2
# use glm for binary trait
# (will also need the fmsb package to calculate the pseudo R2)
null.model <- paste("PC", 1:6, sep = "", collapse = "+") %>%
    paste0("Height~Sex+", .) %>%
    as.formula %>%
    lm(., data = y) %>%
    summary
null.r2 <- null.model$r.squared
```

```{r snp_ldpred2}
beta_inf <- snp_ldpred2_inf(corr, df_beta, h2 = h2_est)
```

##	7. Obtain model PRS

Using Genome wide bed file

(Also Using chromosome separated bed files in tutorial)

Infinitesimal model (grid and auto model also available in tutorial)


```{r obtain_model_PRS}
if(is.null(obj.bigSNP)){
    obj.bigSNP <- snp_attach("EUR.QC.rds")
}
genotype <- obj.bigSNP$genotypes
# calculate PRS for all samples
ind.test <- 1:nrow(genotype)
pred_inf <- big_prodVec(    genotype,
                            beta_inf,
                            ind.row = ind.test,
                            ind.col = info_snp$`_NUM_ID_`)
```

##	8. Get the final performance of the LDpred models


```{r final_performance}
reg.formula <- paste("PC", 1:6, sep = "", collapse = "+") %>%
    paste0("Height~PRS+Sex+", .) %>%
    as.formula
reg.dat <- y
reg.dat$PRS <- pred_inf
inf.model <- lm(reg.formula, dat=reg.dat) %>%
    summary
(result <- data.table(
    infinitesimal = inf.model$r.squared - null.r2,
    null = null.r2
))
```

How much phenotypic variation does the PRS from each model explain?
Infinitesimal = 0.0248696

Grid Model = 0.001746926

Auto Model = 0.1751478


Where is this value?






#	Background

lassosum is one of the dedicated PRS programs which is an R package that uses penalised regression (LASSO) in its approach to PRS calculation.

##	Installing lassosum

Note

The script used here is based on lassosum version 0.4.4

Note

For more details, please refer to lassosum's homepage

You can install lassosum and its dependencies in R with the following command:

```{r install_lassosum}
#install.packages(c("devtools","RcppArmadillo", "data.table", "Matrix"), dependencies=TRUE)
#library(devtools)
#install_github("tshmak/lassosum")
```



##	Required Data

Again, we assume that we have the following files (or you can download it from here):

File Name	Description
Height.QC.gz	The post-QCed summary statistic
EUR.QC.bed	The genotype file after performing some basic filtering
EUR.QC.bim	This file contains the SNPs that passed the basic filtering
EUR.QC.fam	This file contains the samples that passed the basic filtering
EUR.height	This file contains the phenotype of the samples
EUR.cov	This file contains the covariates of the samples
EUR.eigenvec	This file contains the PCs of the samples

##	Running PRS analysis

We can run lassosum as follows:



```{r lassosum_PRS}
library(lassosum)
# Prefer to work with data.table as it speeds up file reading
library(data.table)
library(methods)
library(magrittr)
# For multi-threading, you can use the parallel package and
# invoke cl which is then passed to lassosum.pipeline
library(parallel)
# This will invoke 2 threads.
cl <- makeCluster(2)

sum.stat <- "Height.QC.gz"
bfile <- "EUR.QC"
# Read in and process the covariates
covariate <- fread("EUR.cov")
pcs <- fread("EUR.eigenvec") %>%
    setnames(., colnames(.), c("FID","IID", paste0("PC",1:6)))
# Need as.data.frame here as lassosum doesn't handle data.table
# covariates very well
cov <- merge(covariate, pcs)

# We will need the EUR.hg19 file provided by lassosum
# which are LD regions defined in Berisa and Pickrell (2015) for the European population and the hg19 genome.
ld.file <- "EUR.hg19"
# output prefix
prefix <- "EUR"
# Read in the target phenotype file
target.pheno <- fread("EUR.height")[,c("FID", "IID", "Height")]
# Read in the summary statistics
ss <- fread(sum.stat)
# Remove P-value = 0, which causes problem in the transformation
ss <- ss[!P == 0]
# Transform the P-values into correlation
cor <- p2cor(p = ss$P,
        n = ss$N,
        sign = log(ss$OR)
        )
fam <- fread(paste0(bfile, ".fam"))
fam[,ID:=do.call(paste, c(.SD, sep=":")),.SDcols=c(1:2)]


# Run the lassosum pipeline
# The cluster parameter is used for multi-threading
# You can ignore that if you do not wish to perform multi-threaded processing
out <- lassosum.pipeline(
    cor = cor,
    chr = ss$CHR,
    pos = ss$BP,
    A1 = ss$A1,
    A2 = ss$A2,
    ref.bfile = bfile,
    test.bfile = bfile,
    LDblocks = ld.file,
    cluster=cl
)
# Store the R2 results
target.res <- validate(out, pheno = as.data.frame(target.pheno), covar=as.data.frame(cov))
# Get the maximum R2
r2 <- max(target.res$validation.table$value)^2
```


How much phenotypic variation does the "best-fit" PRS explain?
0.2474679



Where is that value from?


#	Plotting the Results

Plotting the Results
The PRS results corresponding to a range of P-value thresholds obtained by application of the C+T PRS method (eg. using PLINK or PRSice-2) can be visualised using R as follows:


```{r plot1}
# ggplot2 is a handy package for plotting
library(ggplot2)
# generate a pretty format for p-value output
prs.result$print.p <- round(prs.result$P, digits = 3)
prs.result$print.p[!is.na(prs.result$print.p) &
                    prs.result$print.p == 0] <-
    format(prs.result$P[!is.na(prs.result$print.p) &
                            prs.result$print.p == 0], digits = 2)
prs.result$print.p <- sub("e", "*x*10^", prs.result$print.p)
# Initialize ggplot, requiring the threshold as the x-axis (use factor so that it is uniformly distributed)
ggplot(data = prs.result, aes(x = factor(Threshold), y = R2)) +
    # Specify that we want to print p-value on top of the bars
    geom_text(
        aes(label = paste(print.p)),
        vjust = -1.5,
        hjust = 0,
        angle = 45,
        cex = 4,
        parse = T
    )  +
    # Specify the range of the plot, *1.25 to provide enough space for the p-values
    scale_y_continuous(limits = c(0, max(prs.result$R2) * 1.25)) +
    # Specify the axis labels
    xlab(expression(italic(P) - value ~ threshold ~ (italic(P)[T]))) +
    ylab(expression(paste("PRS model fit:  ", R ^ 2))) +
    # Draw a bar plot
    geom_bar(aes(fill = -log10(P)), stat = "identity") +
    # Specify the colors
    scale_fill_gradient2(
        low = "dodgerblue",
        high = "firebrick",
        mid = "dodgerblue",
        midpoint = 1e-4,
        name = bquote(atop(-log[10] ~ model, italic(P) - value),)
    ) +
    # Some beautification of the plot
    theme_classic() + theme(
        axis.title = element_text(face = "bold", size = 18),
        axis.text = element_text(size = 14),
        legend.title = element_text(face = "bold", size =
                                        18),
        legend.text = element_text(size = 14),
        axis.text.x = element_text(angle = 45, hjust =
                                    1)
    )
# save the plot
#ggsave("EUR.height.bar.png", height = 7, width = 7)
```



An example bar plot generated using ggplot2

In addition, we can visualise the relationship between the "best-fit" PRS (which may have been obtained from any of the PRS programs) and the phenotype of interest, coloured according to sex:



```{r plot2}
library(ggplot2)
# Read in the files
prs <- read.table("EUR.0.3.profile", header=T)
height <- read.table("EUR.height", header=T)
sex <- read.table("EUR.cov", header=T)
# Rename the sex
sex$Sex <- as.factor(sex$Sex)
levels(sex$Sex) <- c("Male", "Female")
# Merge the files
dat <- merge(merge(prs, height), sex)
# Start plotting
ggplot(dat, aes(x=SCORE, y=Height, color=Sex))+
    geom_point()+
    theme_classic()+
    labs(x="Polygenic Score", y="Height")
```

An example scatter plot generated using ggplot2

Programs such as PRSice-2 and bigsnpr include numerous options for plotting PRS results.



