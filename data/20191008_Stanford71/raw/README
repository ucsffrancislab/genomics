



#	nohup wget --no-clobber --recursive http://sfgf-download-2.stanford.edu/~sfgf/191008_J00118_0508_AHCHWFBBXY-SFGF-Shaw-GS-13361/ &


for f in $PWD/191008_J00118_0508_AHCHWFBBXY-L00*tar ; do echo $f ; echo "tar -C $PWD -xvf $f" | qsub ; done



for f in 191008_J00118_0508_AHCHWFBBXY-L00*/71*z ; do l=$( basename $f ); l=${l#71-}; l=${l/-*_R/_R}; l=${l/_001./.}; echo $f $l ; done

no leading zeroes
easier to ...

for i in $( seq 1 77 ); do l=$( printf "%02d" $i ); echo $i $l ; echo ${l}_R1.fastq.gz; echo 191008_J00118_0508_AHCHWFBBXY-L00*/71-${i}-*R1*z; echo ${l}_R2.fastq.gz; echo 191008_J00118_0508_AHCHWFBBXY-L00*/71-${i}-*R2*z; done

for i in $( seq 1 77 ); do l=$( printf "%02d" $i ); echo $i $l ; ln -s 191008_J00118_0508_AHCHWFBBXY-L00*/71-${i}-*R1*z ${l}_R1.fastq.gz; ln -s 191008_J00118_0508_AHCHWFBBXY-L00*/71-${i}-*R2*z ${l}_R2.fastq.gz; done



#	Look at adapters. All a bit different as include id tags. Use provided.
for i in $( seq -w 1 77 ) ; do echo "/home/gwendt/.local/BBMap/bbmerge.sh in1=/data/shared/francislab/data/raw/SFGF-Shaw-GS-13361/${i}_R1.fastq.gz in2=/data/shared/francislab/data/raw/SFGF-Shaw-GS-13361/${i}_R2.fastq.gz outa=/data/shared/francislab/data/raw/SFGF-Shaw-GS-13361/${i}.adapters.fa" | qsub -l nodes=1:ppn=8 -l vmem=8gb ; done

#	Trim adapters
BASE=/data/shared/francislab/data/raw/SFGF-Shaw-GS-13361
for i in $( seq -w 76 77 ) ; do echo "/home/gwendt/.local/BBMap/bbduk.sh -Xmx4g in1=${BASE}/${i}_R1.fastq.gz in2=${BASE}/${i}_R2.fastq.gz out1=${BASE}/trimmed/${i}_R1.fastq.gz out2=${BASE}/trimmed/${i}_R2.fastq.gz ref=${BASE}/adapters.fa ktrim=r k=23 mink=11 hdist=1 tbo ordered=t" | qsub -l vmem=16gb -o ${BASE}/trimmed/${i}.bbduk.out -e ${BASE}/trimmed/${i}.bbduk.err ; done





#	Merge laned data
BASE=/data/shared/francislab/data/raw/SFGF-Shaw-GS-13361/trimmed
for i in $( seq -w 1 77 ) ; do echo "zcat ${BASE}/${i}_R1.fastq.gz ${BASE}/${i}_R2.fastq.gz | sed -E 's/ ([[:digit:]]):.*$/\/\1/' | gzip > ${BASE}/${i}.fastq.gz" | qsub ; done




BASE=/data/shared/francislab/data/raw/SFGF-Shaw-GS-13361/trimmed
REF=/data/shared/francislab/refs/
for i in $( seq -w 1 77 ) ; do
echo "${BASE}/${i}_R1.fastq.gz ${BASE}/${i}_R2.fastq.gz > ${BASE}/${i}.fastq.gz"


kallisto quant -b 40 --threads 40 --index /raid/refs/kallisto/${hhv} --output-dir ${basename}.${hhv}.kallisto40 ${f1} ${f2} 2> ${basename}.${hhv}.kallisto40.log


kallisto to human.rna
kallisto to refseqgene
kallisto to GRCh38.cdna
kallisto to GRCh38.ncrna
kallisto to GRCh38.rna

subread hg38
subread hg38.masked

bowtie2 hg38
bowtie2 hg38.masked

bowtie2 to human.rna
bowtie2 to refseqgene
bowtie2 to GRCh38.cdna
bowtie2 to GRCh38.ncrna
bowtie2 to GRCh38.rna


HAWK


done






Awk Sum Squares Standard Deviation (stddev)

zcat /data/shared/francislab/data/raw/SFGF-Shaw-GS-13361/trimmed/*fastq.gz | paste - - - - | cut -f 2 | awk '{ l=length; sum+=l; sumsq+=(l)^2; print "Avg:",sum/NR,"\tStddev:\t"sqrt((sumsq-sum^2/NR)/NR)}' > trimmed.avg_length.ssstdev.txt &



Assign job names to jobs.





################################################## 20191106


#	Trim adapters
BASE=/data/shared/francislab/data/raw/SFGF-Shaw-GS-13361
for i in $( seq -w 1 77 ) ; do
qsub -l vmem=32gb -o ${OUT}.bbduk.out -e ${OUT}.bbduk.err -N bbduk.${i} ${BASE}/trimmed_reads.bash -F ${i}
done


#	Merge all / unpair data
BASE=/data/shared/francislab/data/raw/SFGF-Shaw-GS-13361
for i in $( seq -w 1 77 ) ; do
qsub -N ${i}.merge_trimmed ${BASE}/merge_trimmed.bash -F ${i}
done


New technique of self-calling scripts

./trim_reads.bash

./merge_trimmed_bash

./read_length_analysis.bash



FASTA=/data/shared/francislab/refs/fasta
r1=/data/shared/francislab/data/raw/SFGF-Shaw-GS-13361/trimmed/unpaired/77.fastq.gz
base=${r1%.fastq.gz}
jobbase=$( basename ${base} )
ref=h38au
outbase=${base}.${ref}
threads=8
vmem=8
feature=miRNA
date=$( date "+%Y%m%d%H%M%S" )
qoutbase="${outbase}.bowtie2.e2e"
infile="${qoutbase}.bam"
qoutbase="${outbase}.bowtie2.e2e.featureCounts.${feature}"
f=${qoutbase}.txt
qsub -N ${jobbase}.${ref}.btfc -l nodes=1:ppn=${threads} -l vmem=${vmem}gb \
	-o ${qoutbase}.${date}.out.txt -e ${qoutbase}.${date}.err.txt \
	~/.local/bin/featureCounts.bash -F "-F GFF3 -t ${feature} -g Name -a ${FASTA}/hg38.chr.hsa.gff3 -o ${f} ${infile}"

qsub -N featureCounts -l nodes=1:ppn=${threads} -l vmem=${vmem}gb -o /data/shared/francislab/data/raw/SFGF-Shaw-GS-13361/featureCounts.${date}.out.txt -e /data/shared/francislab/data/raw/SFGF-Shaw-GS-13361/featureCounts.${date}.err.txt ~/.local/bin/featureCounts.bash -F "-T ${threads} -t ${feature} -g Name -a ${FASTA}/hg38.chr.hsa.gff3 -o /data/shared/francislab/data/raw/SFGF-Shaw-GS-13361/featureCounts.txt /data/shared/francislab/data/raw/SFGF-Shaw-GS-13361/trimmed/unpaired/??.h38au.bowtie2.e2e.bam"



source=/data/shared/francislab/data/raw/SFGF-Shaw-GS-13361/trimmed/unpaired
threads=16
vmem=8
date=$( date "+%Y%m%d%H%M%S" )
for feature in miRNA miRNA_primary_transcript ; do
qsub -N ${feature} -l nodes=1:ppn=${threads} -l vmem=${vmem}gb -o ${source}/bowtie2.hsa.featureCounts.${feature}.${date}.out.txt -e ${source}/bowtie2.hsa.featureCounts.${feature}.${date}.err.txt ~/.local/bin/featureCounts.bash -F "-T ${threads} -t ${feature} -g Name -a ${FASTA}/hg38.chr.hsa.gff3 -o ${source}/bowtie2.hsa.featureCounts.${feature}.txt ${source}/??.h38au.bowtie2.e2e.bam"
done










mkdir test
cp /data/shared/francislab/data/raw/20191008_Stanford71/trimmed/unpaired/subread-dna.genes.featureCounts.exon.csv test/

date=$( date "+%Y%m%d%H%M%S" ) ; qsub -N deseq -l vmem=4gb -o /data/shared/francislab/data/raw/20191008_Stanford71/test/subread-dna.genes.featureCounts.exon.csv.deseq.${date}.out -e /data/shared/francislab/data/raw/20191008_Stanford71/test/subread-dna.genes.featureCounts.exon.csv.deseq.${date}.err ~/.local/bin/deseq.R -F "-f /data/shared/francislab/data/raw/20191008_Stanford71/test/subread-dna.genes.featureCounts.exon.csv -m /data/shared/francislab/data/raw/20191008_Stanford71/metadata.csv"



for f in /data/shared/francislab/data/raw/20191008_Stanford71/trimmed/unpaired/sub*featureCounts*.csv ; do
last_arg=$( tail -n +2 $f | head -1 | awk '{print $NF}' )
echo $last_arg
last_arg_dir="${last_arg%/*}/"
echo $last_arg_dir
last_arg_file=${last_arg##*/}
echo $last_arg_file
last_arg_file_base=".${last_arg_file#*.}"
echo $last_arg_file_base
echo sed -e "2s\"${last_arg_dir}\"\"g" -e "2s\"${last_arg_file_base}\"\"g" -i ${f}
sed -e "2s\"${last_arg_dir}\"s\"g" -e "2s\"${last_arg_file_base}\"\"g" -i ${f}
done


date=$( date "+%Y%m%d%H%M%S" )
for f in /francislab/data1/raw/20191008_Stanford71/trimmed/unpaired/sub*featureCounts*.csv ; do
qsub -N deseq -l vmem=4gb -o ${f}.deseq.${date}.out -e ${f}.deseq.${date}.err ~/.local/bin/deseq.R -F "-f ${f} -m /francislab/data1/raw/20191008_Stanford71/metadata.csv"
done




export featureCounts="/francislab/data1/raw/20191008_Stanford71/trimmed/unpaired/h38au.bowtie2-e2e.unmapped.kraken2.standard.summary.csv"
export metadata="/francislab/data1/raw/20191008_Stanford71/metadata.csv"
jupyter_nbconvert.bash --to notebook --execute ~/github/ucsffrancislab/genomics/scripts/deseq.ipynb --output bowtie2-e2e.unmapped.kraken2.standard.summary.deseq.ipynb




dir="/francislab/data1/raw/20191008_Stanford71/trimmed/unpaired"
export metadata="/francislab/data1/raw/20191008_Stanford71/metadata.csv"
for suffix in kraken2.standard blastn.viral.masked blastn.viral.raw blastn.viral ; do
export featureCounts="${dir}/bowtie2-e2e.unmapped.${suffix}.summary.csv"
jupyter_nbconvert.bash --to notebook --execute ~/.local/bin/deseq.ipynb --output ${featureCounts}.deseq.ipynb --ExecutePreprocessor.timeout=600
done
for a in subread-dna subread-rna bowtie2-e2e ; do
for b in hsa.featureCounts.miRNA_primary_transcript hsa.featureCounts.miRNA genes.featureCounts.exon ; do
export featureCounts="${dir}/${a}.${b}.csv"
jupyter_nbconvert.bash --to notebook --execute ~/.local/bin/deseq.ipynb --output ${featureCounts}.deseq.ipynb --ExecutePreprocessor.timeout=600
done ; done





subread-rna.genes.featureCounts.CDS.csv
subread-dna.hsa.featureCounts.miRNA_primary_transcript.csv
subread-dna.hsa.featureCounts.miRNA.csv
subread-dna.genes.featureCounts.stop_codon.csv
subread-dna.genes.featureCounts.start_codon.csv
subread-dna.genes.featureCounts.exon.csv
subread-dna.genes.featureCounts.CDS.csv
subread-rna.hsa.featureCounts.miRNA_primary_transcript.csv
subread-rna.hsa.featureCounts.miRNA.csv
subread-rna.genes.featureCounts.stop_codon.csv
subread-rna.genes.featureCounts.start_codon.csv
subread-rna.genes.featureCounts.exon.csv
bowtie2-e2e.hsa.featureCounts.miRNA.csv
bowtie2-e2e.hsa.featureCounts.miRNA_primary_transcript.csv
bowtie2-e2e.genes.featureCounts.exon.csv
bowtie2-e2e.genes.featureCounts.CDS.csv
bowtie2-e2e.genes.featureCounts.start_codon.csv
bowtie2-e2e.genes.featureCounts.stop_codon.csv

for a in subread-dna subread-rna bowtie2-e2e ; do
for b in hsa.featureCounts.miRNA_primary_transcript hsa.featureCounts.miRNA ; do
rename ${a}.${b} ${a}.${b}.Name ${a}.${b}.*
done
for b in genes.featureCounts.exon genes.featureCounts.start_codon genes.featureCounts.stop_codon genes.featureCounts.CDS ; do
rename ${a}.${b} ${a}.${b}.gene_id ${a}.${b}.*
done
done




Investigate read lengths during preprocessing.

DIR=/francislab/data1/raw/20191008_Stanford71
for f in ${DIR}/*fastq.gz ; do
read_length_hist.bash $f
done

Then sum up hist data counts. DON'T RE-READ RAW FILES

DIR=/francislab/data1/raw/20191008_Stanford71
zcat ${DIR}/*_R?.fastq.gz.length_hist.csv.gz | awk '{c[$2]+=$1}END{for(n in c){print n,c[n]}}' | sort -k2n | gzip > ${DIR}/all_R.length_hist.csv.gz &

