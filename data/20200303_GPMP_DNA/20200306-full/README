


	
N is normal samples (blood samples). Just for WGS, not available for rna-seq
NE means non-enhancing.
E means enhancing.

Brain tissue.
Case numbers are the prefixed with "SF" of each file name. eg  SF12210"

All this is whole genome sequencing data: so DNA. I will upload the bulk RNA now. 



Blood samples are normal (act as control), but they come from patients with brain cancer. It is my understanding their blood doesnt express the same tumor markers as the tumor specimens.

No difference between batch 1 and two. Just batch 1 was sequenced first, batch 2 was second.

P prefix is another reference to patient that was used by the sequencing facility. Please use SF number. (eg SF#####)

To specify: batch 1 are trimmed samples. (I used trim galore under anaconda3)
batch2 is untrimmed.



Thank you for making the directory. I will use it from now on to share data with you and the francis lab. I have uploaded the RNA bulk seq to /data/fcatalan/WGS. Please note that one sample (SF12888-NE) is trimmed while the rest are not. This too was trimmed using trimgalore.

	


rename _R1.h38 .h38 SF12[12]*_R1.h38au*
rename _R1.h38 .h38 SF124*_R1.h38au*
rename _R1.h38 .h38 SF123*_R1.h38au*







#for suffix in viral.summary viral.summary.sum-genus viral.summary.sum-species nr.summary nr.summary.sum-genus nr.summary.sum-species ; do
for suffix in nr.summary nr.summary.sum-genus nr.summary.sum-species ; do
echo $suffix
merge_summaries.py --int --output unmapped.bam.diamond.${suffix}.csv.gz trimmed/length/*.h38au.bowtie2-e2e.unmapped.diamond.${suffix}.txt.gz
merge_summaries.py --output unmapped.bam.diamond.${suffix}.normalized.csv.gz trimmed/length/*.h38au.bowtie2-e2e.unmapped.diamond.${suffix}.normalized.txt.gz
done






DIR=/francislab/data1/working/20200303_GPMP_DNA/20200306-full/trimmed/length
zcat ${DIR}/*R?.fastq.gz | paste - - - - | cut -f 2 | awk '{print length($0)}' | sort | uniq -c | sort -k2n | gzip > ${DIR}/all_R.length_hist.csv.gz &

DIR=/francislab/data1/working/20200303_GPMP_DNA/20200306-full/trimmed
zcat ${DIR}/*R?.fastq.gz | paste - - - - | cut -f 2 | awk '{print length($0)}' | sort | uniq -c | sort -k2n | gzip > ${DIR}/all_R.length_hist.csv.gz &




DIR=/francislab/data1/working/20200303_GPMP_DNA/20200306-full
for f in ${DIR}/trimmed/*fastq.gz ${DIR}/trimmed/length/*fastq.gz ; do
echo read_length_hist_scratch.bash $f
done | qsub -N 20200303work -l nodes=1:ppn=8 -l vmem=16gb \
-j oe -o ${DIR}/read_length_hist.bash.out 

DIR=/francislab/data1/working/20200303_GPMP_DNA/20200306-full
for f in ${DIR}/trimmed/*fastq.gz ${DIR}/trimmed/length/*fastq.gz ; do
qsub -N $(basename $f) -l nodes=1:ppn=8 -l vmem=16gb \
-j oe -o ${f}.length_hist.bash.out ~/.local/bin/read_length_hist_scratch.bash -F "$f"
done









DIR=/francislab/data1/working/20200303_GPMP_DNA/20200306-full
for f in ${DIR}/trimmed/length/SF124*fastq.gz ; do
qsub -N $(basename $f) -l nodes=1:ppn=8 -l vmem=16gb -h \
-j oe -o ${f}.length_hist.bash.out ~/.local/bin/read_length_hist_scratch.bash -F "$f"
done




Then sum up hist data counts. DON'T RE-READ RAW FILES

DIR=/francislab/data1/working/20200303_GPMP_DNA/20200306-full/trimmed
zcat ${DIR}/*_R?.fastq.gz.length_hist.csv.gz | awk '{c[$2]+=$1}END{for(n in c){print c[n],n}}' | sort -k2n | gzip > ${DIR}/all_R.length_hist.csv.gz
DIR=/francislab/data1/working/20200303_GPMP_DNA/20200306-full/trimmed/length
zcat ${DIR}/*_R?.fastq.gz.length_hist.csv.gz | awk '{c[$2]+=$1}END{for(n in c){print c[n],n}}' | sort -k2n | gzip > ${DIR}/all_R.length_hist.csv.gz




