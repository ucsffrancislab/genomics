

/data/fcatalan/WGS_data


rsync -avz --progress /data/fcatalan/WGS_data/ /francislab/data1/raw/20200309_GPMP_RNA/WGS_data/

Thank you for making the directory. I will use it from now on to share data with you and the francis lab. I have uploaded the RNA bulk seq to /data/fcatalan/WGS. Please note that one sample (SF12888-NE) is trimmed while the rest are not. This too was trimmed using trimgalore.

date=$( date "+%Y%m%d%H%M%S" )
dir=/francislab/data1/raw/20200309_GPMP_RNA/WGS_data/cohort2_rna-seq/
f=${dir}/P484SF12288-NE_S2_L001_R2_001_val_2.fq
echo "gzip ${f}" | qsub -N gzip -o ${f}.gzip.${date}.out.txt -e ${f}.gzip.${date}.err.txt




mkdir fastq

for f in WGS_data/cohort*/*q.gz; do
b=$( basename $f .fq.gz );
b=$( basename $b .fastq.gz );
b=${b%%_val_?};
b=${b%%_001};
b=${b/_L00?/};
b=${b/-*-/-};
b=${b/E_S9/-E_S9};
b=${b/_S*_/_};
b=${b/P*SF/SF};
echo $b;
ln -s ../$f fastq/$b.fastq.gz;
done









sort uses A LOT of tmp disk space which can run out.

DIR=/francislab/data1/raw/20200309_GPMP_RNA
for f in ${DIR}/fastq/*fastq.gz ; do
echo read_length_hist.bash $f
done | qsub -N 20200309raw -l nodes=1:ppn=8 -l vmem=16gb \
-j oe -o ${DIR}/read_length_hist.bash.out 



Then sum up hist data counts. DON'T RE-READ RAW FILES

DIR=/francislab/data1/raw/20200309_GPMP_RNA/fastq
zcat ${DIR}/*_R?.fastq.gz.length_hist.csv.gz | awk '{c[$2]+=$1}END{for(n in c){print c[n],n}}' | sort -k2n | gzip > ${DIR}/all_R.length_hist.csv.gz &


