

https://www.ebi.ac.uk/arrayexpress/files/E-GEUV-1/processed/
https://www.ebi.ac.uk/ena/browser/view/PRJEB3366
https://www.ebi.ac.uk/ena/browser/view/PRJEB3365


samtools view -c HG00096.1.M_111124_6.bam
53116228

samtools view -f 4 -c HG00096.1.M_111124_6.bam
761440



qsub -N wget -l nodes=1:ppn=4 -l vmem=8gb \


date=$( date "+%Y%m%d%H%M%S" )
dir=/francislab/data1/raw/Geuvadis
qsub -N wget \
	-o ${dir}/wget_files.${date}.out.txt \
	-e ${dir}/wget_files.${date}.err.txt \
	${dir}/wget_files.bash


I am a bit concerned that files are incomplete cause their server can't handle the load.
for b in bam/*bam ; do echo $b; samtools quickcheck ${b} && echo 'all ok' || echo 'fail!' ; done
But all appears well.






git clone https://github.com/chmille4/bamReadDepther.git
cd bamReadDepther
gcc -lstdc++ -o bamReadDepther bamReadDepther.cpp 


count_bai_reads.bash /francislab/data1/raw/Geuvadis/bam/*bam.bai


./samtools_count.bash

...  WAIT ...



./aggregate_read_counts.bash

Check
awk -F, '( $4 != $5 )' read_counts.csv
awk -F, '( $7 != $8 )' read_counts.csv
Nothing! BAM counts are the same as BAI counts.

Remove bam counting and rerun.

./aggregate_read_counts.bash




aws s3 sync --exclude \* --include \*bam /francislab/data1/raw/Geuvadis/bam/ s3://geuvadis-bam/


