

See ../../20200529_Raleigh_WES/20200610-HKLE_chimera

20200603-TCGA-GBMLGG-WGS/20201027-hkle-chimera






import pandas as pd
df=pd.read_csv("out/02-2483-01A.SVAs_and_HERVs_KWHE.hkle/02-2483-01A.SVAs_and_HERVs_KWHE.bowtie2.SVA_F.very_sensitive_local.unpaired.aligned.pre.bowtie2.hg38.Q20.rc_insertion_points", sep='|', header=None, names=['chromosome','position'])
df['rp']='pre'
df['dir']='rc'
df['pup']='u'
df['hkle']='SVA_F'
udf=df.groupby(df.columns.tolist(),as_index=False).size().to_frame('samplename')

#	as_index=False seems to have no impact on output


udf.columns=pd.MultiIndex.from_product([['u'],['20'],['SVA_F']])




df=pd.read_csv('merge2.csv.gz',header=[0,1,2,3,4,5],index_col=[0,1])





Argument list is long so created -p option for script.

nohup ./merge_insertion_points.py -o merged.0-D.csv.gz -p 'out/[0-D]*.SVAs_and_HERVs_KWHE.hkle/*.SVAs_and_HERVs_KWHE.bowtie2.*.very_sensitive_local.*.aligned.*.bowtie2.hg38.*.*ts' &


Ran out of memory.




Merge pre/post and forward/reverse and round 1000


mkdir premerge1k
for dir in out/*.SVAs_and_HERVs_KWHE.hkle ; do
sample=$( basename $dir )
sample=${sample%%.*}
for hkle in SVA_A SVA_B SVA_C SVA_D SVA_E SVA_F HERVK113 ; do
for pup in paired unpaired ; do
for mapq in Q00 Q10 Q20 ; do
echo "${sample}-${hkle}-${pup}-${mapq}"
sort ${dir}/*.bowtie2.${hkle}.very_sensitive_local.${pup}.aligned.{pre,post}.bowtie2.hg38.${mapq}.{ins,rc_ins}*ts | awk 'BEGIN{FS=OFS="|"}{print $1,int($2/1000)*1000}' > premerge1k/${sample}.${hkle}.${pup}.${mapq}.all_insertion_points
done ; done ; done ; done


nohup ./merge_insertion_points.py -o merged.0-D.rounded1k.csv.gz -p 'premerge1k/*ts' > merge_insertion_points.all1k.out 2> merge_insertion_points.all1k.err &





nohup ./merge_insertion_points.bash > merge_insertion_points.out 2> merge_insertion_points.err &


BOX="https://dav.box.com/dav/Francis _Lab_Share/20201123 20200603-TCGA-GBMLGG-WGS 20201029-hkle-chimera"

curl -netrc -X MKCOL "${BOX}/"

for f in *chr2[01].*gz ; do
echo $f
curl -netrc -T ${f} "${BOX}/"
done


import pandas as pd
df=pd.read_csv("merged/merged.0-D.rounded1k.chr2.T.csv.gz",index_col=[0,1,2,3],header=[0,1])
df=pd.read_csv("merged/merged.0-D.rounded1k.chr2.csv.gz",header=[0,1,2,3],index_col=[0,1])



import pandas as pd
df=pd.read_csv("merged.0-D.rounded1k----.T.csv.gz",index_col=[0,1,2,3],header=[0,1])
df=pd.read_csv("merged.0-D.rounded1k----.csv.gz",header=[0,1,2,3],index_col=[0,1])



mkdir premerge10k
for dir in out/*.SVAs_and_HERVs_KWHE.hkle ; do
sample=$( basename $dir )
sample=${sample%%.*}
for hkle in SVA_A SVA_B SVA_C SVA_D SVA_E SVA_F HERVK113 ; do
for pup in paired unpaired ; do
for mapq in Q00 Q10 Q20 ; do
echo "${sample}-${hkle}-${pup}-${mapq}"
sort ${dir}/*.bowtie2.${hkle}.very_sensitive_local.${pup}.aligned.{pre,post}.bowtie2.hg38.${mapq}.{ins,rc_ins}*ts | awk 'BEGIN{FS=OFS="|"}{print $1,int($2/10000)*10000}' > premerge10k/${sample}.${hkle}.${pup}.${mapq}.all_insertion_points
done ; done ; done ; done


nohup ./merge_insertion_points.py -o merged.0-D.rounded10k.csv.gz -p 'premerge10k/*ts' > merge_insertion_points.all10k.out 2> merge_insertion_points.all10k.err &

nohup ./merge_insertion_points.py -o merged.rounded10k.csv.gz -p 'premerge10k/*ts' > merge_insertion_points.all10k.out 2> merge_insertion_points.all10k.err &




echo ${command} | qsub -N ${out} -l nodes=1:ppn=16 -l vmem=125gb -l feature=nocommunal -o /francislab/data1/raw/20201127-EV_CATS/STAR_test/${out}.out -e /francislab/data1/raw/20201127-EV_CATS/STAR_test/${out}.err


echo "/francislab/data1/working/20200603-TCGA-GBMLGG-WGS/20201029-hkle-chimera/merge_insertion_points.py -o /francislab/data1/working/20200603-TCGA-GBMLGG-WGS/20201029-hkle-chimera/merged.rounded1k.csv.gz -p '/francislab/data1/working/20200603-TCGA-GBMLGG-WGS/20201029-hkle-chimera/premerge1k/*ts'" | qsub -N merge -l nodes=1:ppn=64 -l vmem=500gb -l feature=nocommunal -o /francislab/data1/working/20200603-TCGA-GBMLGG-WGS/20201029-hkle-chimera/merge_insertion_points.all1k.out -e /francislab/data1/working/20200603-TCGA-GBMLGG-WGS/20201029-hkle-chimera/merge_insertion_points.all1k.err



echo "/francislab/data1/working/20200603-TCGA-GBMLGG-WGS/20201029-hkle-chimera/cull_matrix.py /francislab/data1/working/20200603-TCGA-GBMLGG-WGS/20201029-hkle-chimera/merged.rounded10k.csv.gz" | qsub -N cull10k -l nodes=1:ppn=64 -l vmem=500gb -l feature=nocommunal -o /francislab/data1/working/20200603-TCGA-GBMLGG-WGS/20201029-hkle-chimera/merge_insertion_points.all10k.cull.out -e /francislab/data1/working/20200603-TCGA-GBMLGG-WGS/20201029-hkle-chimera/merge_insertion_points.all10k.cull.err

echo "/francislab/data1/working/20200603-TCGA-GBMLGG-WGS/20201029-hkle-chimera/cull_matrix.py /francislab/data1/working/20200603-TCGA-GBMLGG-WGS/20201029-hkle-chimera/merged.rounded1k.csv.gz" | qsub -N cull1k -l nodes=1:ppn=64 -l vmem=500gb -l feature=nocommunal -o /francislab/data1/working/20200603-TCGA-GBMLGG-WGS/20201029-hkle-chimera/merge_insertion_points.all1k.cull.out -e /francislab/data1/working/20200603-TCGA-GBMLGG-WGS/20201029-hkle-chimera/merge_insertion_points.all1k.cull.err




BOX="https://dav.box.com/dav/Francis _Lab_Share/20201123 20200603-TCGA-GBMLGG-WGS 20201029-hkle-chimera"

curl -netrc -T merged.rounded10k.csv.gz "${BOX}/"
curl -netrc -T merged.rounded10k.T.csv.gz "${BOX}/"
curl -netrc -T merged.rounded10k.culled.csv.gz "${BOX}/"
curl -netrc -T merged.rounded10k.culled.T.csv.gz "${BOX}/"

BOX="https://dav.box.com/dav/Francis _Lab_Share/20201123 20200603-TCGA-GBMLGG-WGS 20201029-hkle-chimera/merged1k-chromosome"
curl -netrc -X MKCOL "${BOX}/"

for f in merged1k/*csv.gz; do 
echo $( basename $f )
curl -netrc -T ${f} "${BOX}/"
done


curl -netrc -T merged.rounded1k.csv.gz "${BOX}/"
curl -netrc -T merged.rounded1k.T.csv.gz "${BOX}/"
curl -netrc -T merged.rounded1k.culled.csv.gz "${BOX}/"
curl -netrc -T merged.rounded1k.culled.T.csv.gz "${BOX}/"


--------------------------------------------------
20210119


nohup ./merge_insertion_points.bash > merge_insertion_points.out 2> merge_insertion_points.err &

nohup ./cull_matrix.py 20210119-merged/merged.rounded*.*.Q??.csv.gz > cull_matrix.out 2> cull_matrix.err &

BOX="https://dav.box.com/dav/Francis _Lab_Share/20201123 20200603-TCGA-GBMLGG-WGS 20201029-hkle-chimera/20210119-merged"
curl -netrc -X MKCOL "${BOX}/"

for f in 20210119-merged/*csv.gz; do 
echo $( basename $f )
curl -netrc -T ${f} "${BOX}/"
done









--------------------------------------------------
20210218


while read filename ; do
echo $filename
cat ${filename} | paste - - | wc -l > ${filename}.read_count
done < <( find out -name \*fasta )

while read filename ; do
echo $filename
cat ${filename} | wc -l > ${filename}.count
done < <( find out -name \*points )









--------------------------------------------------
20210414
nohup python3 ./merge_insertion_points.py -o focused.csv.gz -p premerge1k/*.paired.Q20.* > focused.out 2> focused.err &


BOX="https://dav.box.com/dav/Francis _Lab_Share/20201123 20200603-TCGA-GBMLGG-WGS 20201029-hkle-chimera"

curl -netrc -X MKCOL "${BOX}/"

curl -netrc -T focused.csv.gz "${BOX}/"
curl -netrc -T focused.T.csv.gz "${BOX}/"







--------------------------------------------------
20210813


Select just the unaligned mate

paste <( cat out/TQ-A8XE-10A.SVAs_and_HERVs_KWHE.hkle/TQ-A8XE-10A.SVAs_and_HERVs_KWHE.bowtie2.HERVK113.very_sensitive_local.paired.aligned.?.p*_1.fasta | paste - - ) <( cat out/TQ-A8XE-10A.SVAs_and_HERVs_KWHE.hkle/TQ-A8XE-10A.SVAs_and_HERVs_KWHE.bowtie2.HERVK113.very_sensitive_local.paired.aligned.?.p*_2.fasta | paste - - ) | head | awk -F"\t" '{if(length($2)>length($4)){print $1;print $2}else{print $3;print $4}}'


mkdir mateonly
for d in out/*hkle ; do
echo $d
s=$( basename $d .SVAs_and_HERVs_KWHE.hkle )
for hkle in HERVK113 SVA_A SVA_B SVA_C SVA_D SVA_E SVA_F ; do
echo $hkle
b="${d}/${s}.SVAs_and_HERVs_KWHE.bowtie2.${hkle}.very_sensitive_local.paired.aligned"
paste <( cat ${b}.?.p*_1.fasta | paste - - ) <( cat ${b}.?.p*_2.fasta | paste - - ) | awk -F"\t" '{if(length($2)>length($4)){print $1;print $2}else{print $3;print $4}}' > mateonly/${s}.${hkle}.fasta
done
done


date=$( date "+%Y%m%d%H%M%S" )
sbatch="sbatch --mail-user=George.Wendt@ucsf.edu --mail-type=FAIL "

for f in *fasta; do 
echo $f
if [ ! -f "${f}.bam" ] ; then
${sbatch} --job-name=${f} --nodes=1 --ntasks=2 --mem=8G --output=${PWD}/${f}.${date}.txt ~/.local/bin/bowtie2.bash --threads 8 --very-sensitive -x /francislab/data1/refs/sources/hgdownload.cse.ucsc.edu/goldenPath/hg38/bigZips/latest/hg38.chrXYM_alts -f -U ${PWD}/${f} --sort --output ${PWD}/${f}.bam
fi
done


for b in *bam; do 
echo $b
samtools view -F4 $b | awk -F"\t" '{print $3":"int($4/1000)*1000}' | sort -t: -k1,1 -k2n | uniq -c > $b.1000.txt
samtools view -F4 $b | awk -F"\t" '{print $3":"int($4/10000)*10000}' | sort -t: -k1,1 -k2n | uniq -c > $b.10000.txt
samtools view -F4 $b | awk -F"\t" '{print $3":"int($4/100000)*100000}' | sort -t: -k1,1 -k2n | uniq -c > $b.100000.txt
done

for i in 1000 10000 100000 ; do
for hkle in HERVK113 SVA_A SVA_B SVA_C SVA_D SVA_E SVA_F ; do
echo ${hkle}-${i}
python3 ~/.local/bin/merge_uniq-c.py --int --output ${hkle}.${i}.csv *.${hkle}.fasta.bam.${i}.txt
done ; done


for f in *.fasta.average_length.txt; do
b=$( basename $f .fasta.average_length.txt )
c=$( cat $f )
echo ${b},${c}
done | sed 's/\./,/g' | gzip > average_length.csv.gz



