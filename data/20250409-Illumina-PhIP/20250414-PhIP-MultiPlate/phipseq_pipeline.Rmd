#!/usr/bin/env Rscript

args <- commandArgs()
fname <- normalizePath(sub("--file=", "", args[grepl("--file=", args)]))
thisfile <- readLines(fname)
newfname <- paste0(tempdir(), "/", basename(fname))
writeLines(thisfile[-1:-which(thisfile == "q(\"no\")")], newfname)


#       argparse (as opposed to optparse) allow the "append" action and the "required" option.
library("argparse")
args=commandArgs()
scriptname=sub("--file=", "", args[grepl("--file=", args)])
parser <- ArgumentParser(description=scriptname)

parser$add_argument("-i", "--input", type="character",
	help="input file", metavar="filename",
	default = "/francislab/data1/working/20250409-Illumina-PhIP/20250414-PhIP-MultiPlate/out.123456131415161718/Counts.csv")

parser$add_argument("-o", "--output", type="character", default=paste0(getwd(),"/PhIPseq_ChatGPT_1"),
	help="output file base [default=%(default)s]", metavar="file base")

opt <- parser$parse_args()

rmarkdown::render(newfname, output_dir = dirname(opt$output), output_file = paste0(opt$output,'.html') )

q("no")





---
title: "PhIP-seq (VirScan) QC, Normalization and Visualization"
author: "Jake and ChatGPT"
date: "2025-10-21"
output:
  html_document:
    fig_width: 12
    fig_height: 8
---

```{r setup, message=FALSE, warning=FALSE, results='hide'}

#	BiocManager::install('edgeR')

# Required packages
packages <- c(
  "tidyverse", "data.table", "edgeR", "limma", "ggplot2", 
  "RColorBrewer", "pheatmap"
)
lapply(packages, function(p) if (!requireNamespace(p, quietly=TRUE)) install.packages(p))
lapply(packages, library, character.only=TRUE)
```



#	1. Load and parse input

# Path to your merged CSV

```{r}
csv_file <- opt$input
```

# Read all lines to handle 9 metadata rows

```{r}
raw_lines <- readLines(csv_file)
```

# Determine number of header/meta rows (you said 9)

```{r}
meta_rows <- 9
```

# Read metadata rows separately

```{r}
meta_df <- lapply(1:meta_rows, function(i) fread(csv_file, nrows=1, skip=i-1, header=FALSE))
names(meta_df) <- c(
	"sample_id", "subject", "path", "type", "study", "group",
	"age", "sex", "plate"
)
```

# Extract the column names (sample IDs) from first metadata row

```{r}
sample_ids <- meta_df$sample_id[1, -c(1,2)] |> as.character()
```

# Combine metadata into one tidy data frame

```{r mete}
sample_metadata <- tibble(
	sample = sample_ids,
	subject = as.character(meta_df$subject[1, -c(1,2)]),
	path = as.character(meta_df$path[1, -c(1,2)]),
	type = as.character(meta_df$type[1, -c(1,2)]),
	study = as.character(meta_df$study[1, -c(1,2)]),
	group = as.character(meta_df$group[1, -c(1,2)]),
	age = as.numeric(as.character(meta_df$age[1, -c(1,2)])),
	sex = as.character(meta_df$sex[1, -c(1,2)]),
	plate = as.numeric(as.character(meta_df$plate[1, -c(1,2)]))
)
```

# Read the count matrix (skip metadata rows)

```{r fread}
counts_df <- fread(csv_file, skip=meta_rows)
```

# Rename the first two columns

```{r rename}
names(counts_df)[1:2] <- c("id", "species")
```

# Keep numeric columns only (counts)

```{r keepnumeri}
counts_mat <- counts_df |>
	select(-species) |>
	column_to_rownames("id") |>
	as.matrix()
```

# Confirm alignment

```{r all}
all(colnames(counts_mat) == sample_metadata$sample)
```




#	2. Basic quality control

# Library sizes per sample

```{r libsize}
lib_sizes <- colSums(counts_mat, na.rm=TRUE)
sample_metadata$lib_size <- lib_sizes
```

# Plot library sizes

```{r plotlibrary}
ggplot(sample_metadata, aes(x=as.factor(plate), y=lib_size, fill=type)) +
	geom_boxplot(outlier.shape=NA) +
	geom_jitter(width=0.2, size=1) +
	scale_y_log10() +
	theme_bw() +
	labs(title="Library sizes per plate", y="Total reads (log10)")
```

# Fraction mapped to top 100 peptides (quick overamplification check)

```{r fractionmapp}
top_frac <- apply(counts_mat, 2, function(x) sum(sort(x, decreasing=TRUE)[1:100]) / sum(x))
sample_metadata$top100_frac <- top_frac

ggplot(sample_metadata, aes(x=lib_size, y=top100_frac, color=type)) +
	geom_point(size=2) +
	scale_x_log10() + theme_bw() +
	labs(title="Top 100 peptide fraction vs library size",
	x="Library size (log10)", y="Fraction in top 100 peptides")
```





#	3. Filter low-count peptides

# Keep peptides with CPM > 1 in at least 3 samples

```{r dgelist}
dge <- DGEList(counts = counts_mat)
dge[1:5,1:5]
```


```{r}
keep <- rowSums(cpm(dge) > 1) >= 3
dge <- dge[keep, , keep.lib.sizes=FALSE]
nrow(dge)
```




#	4. Normalization (TMM)


```{r normfactor}
dge <- calcNormFactors(dge, method="TMM")
dge[1:5,1:5]
```

```{r}
logCPM <- cpm(dge, log=TRUE, prior.count=1)
logCPM[1:5,1:5]
```

# Add normalized library size factor

```{r}
sample_metadata$norm_factor <- dge$samples$norm.factors
```


#	5. PCA before and after normalization

# Raw logCPM before norm

```{r logcpmraw}
logCPM_raw <- cpm(DGEList(counts=counts_mat), log=TRUE, prior.count=1)
logCPM_raw[1:5,1:5]
```

# Function to run PCA and plot

```{r pca}
plot_pca <- function(mat, title) {
  pca <- prcomp(t(mat), scale. = TRUE)
  df <- data.frame(pca$x[, 1:2], sample_metadata)
  df$letter <- LETTERS[match(df$plate, c(1:6, 13:18))]

  # Unique plate-to-letter mapping for legend
  plate_labels <- df[!duplicated(df$plate), c("plate", "letter")]
  plate_labels <- plate_labels[order(plate_labels$plate), ]
  legend_labels <- paste0(plate_labels$letter, " = Plate ", plate_labels$plate)

  ggplot(df, aes(PC1, PC2, color = type)) +
    # Draw the sample letters
    geom_text(aes(label = letter), size = 4, fontface = "bold", show.legend = FALSE) +
    # Add dummy points *off the plot area* to create a dot legend for type
    geom_point(aes(x = Inf, y = Inf), size = 3, show.legend = TRUE) +
    # Add dummy (invisible) points for the plate-letter mapping legend
    geom_point(aes(shape = as.factor(plate)), alpha = 0) +
    scale_shape_discrete(
      name = "Plate (Letter Mapping)",
      labels = legend_labels
    ) +
    theme_bw() +
    labs(title = title)
}


print(plot_pca(logCPM_raw, "PCA (raw logCPM)"))
print(plot_pca(logCPM, "PCA (TMM-normalized logCPM)"))
```




#	6. Control sample consistency check


# Mean logCPM per control type

```{r logcpm}
control_means <- sample_metadata %>%
	filter(type %in% c("input","Phage Library","commercial serum control")) %>%
	pull(sample)

if(length(control_means) > 0){
#	corr_mat <- cor(logCPM[, control_means], method="spearman")
#	pheatmap(corr_mat, main="Control sample correlation (Spearman)",
#	color=colorRampPalette(brewer.pal(9, "Blues"))(100))
#	
#	The data frame (logCPM) does not have any column names in this version
#	Error in `logCPM[, control_means]`:
#	! subscript out of bounds
#	Backtrace:
#	    ▆
#	 1. └─stats::cor(logCPM[, control_means], method = "spearman")
#	 2.   └─base::is.data.frame(x)
#	
#	Quitting from phipseq_pipeline.Rmd:241-255 [logcpm]
#	                                                                                                             
#	Execution halted
}
```


```{r}
dim(logCPM)
```

```{r}
logCPM[1:5,1:5]
```

```{r}
control_means
```




#	7. Plate-level median check (for potential scaling)



```{r median}
plate_medians <- sample_metadata %>%
	group_by(plate) %>%
	summarise(median_lib = median(lib_size))

ggplot(plate_medians, aes(x=as.factor(plate), y=median_lib)) +
	geom_bar(stat="identity", fill="steelblue") +
	theme_bw() + scale_y_log10() +
	labs(title="Median library size per plate (pre-normalization)")
```




#	8. Save normalized data


```{r save}
#write.csv(logCPM, file="normalized_logCPM.csv", quote=FALSE)
#write.csv(sample_metadata, file="sample_metadata_parsed.csv", row.names=FALSE)

print(dirname(opt$output))
print(paste0(dirname(opt$output),"/normalized_logCPM.csv"))
print(paste0(dirname(opt$output),"/sample_metadata_parsed.csv"))
write.csv(logCPM, file = paste0(dirname(opt$output),"/normalized_logCPM.csv"), quote = FALSE)
write.csv(sample_metadata, file = paste0(dirname(opt$output),"/sample_metadata_parsed.csv"), row.names = FALSE)
message("Saved normalized_logCPM_fixed.csv and sample_metadata_parsed_fixed.csv")
```





